"""
è¯­éŸ³æœåŠ¡ä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ–°çš„è¯­éŸ³æœåŠ¡è¿›è¡ŒASRå’ŒTTS
"""

import asyncio
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from core.voice_config import create_voice_config, get_voice_provider_status
from core.enhanced_voice_services import EnhancedASRService, EnhancedTTSService, VoiceProvider

async def example_asr():
    """ASRä½¿ç”¨ç¤ºä¾‹"""
    print("=== ASRä½¿ç”¨ç¤ºä¾‹ ===")
    
    # åˆ›å»ºé…ç½®
    voice_config = create_voice_config()
    asr_service = EnhancedASRService(voice_config)
    
    print(f"ä½¿ç”¨ASRæä¾›å•†: {voice_config.primary_asr_provider.value}")
    
    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦çœŸå®çš„éŸ³é¢‘æ•°æ®
    # åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œaudio_dataåº”è¯¥æ˜¯ä»éº¦å…‹é£æˆ–æ–‡ä»¶è¯»å–çš„éŸ³é¢‘æ•°æ®
    print("æ³¨æ„ï¼šéœ€è¦çœŸå®éŸ³é¢‘æ•°æ®è¿›è¡Œæµ‹è¯•")
    print("ç¤ºä¾‹ä»£ç :")
    print("""
    # ä»æ–‡ä»¶è¯»å–éŸ³é¢‘
    with open('audio.wav', 'rb') as f:
        audio_data = f.read()
    
    # è½¬å†™éŸ³é¢‘
    text = await asr_service.transcribe(audio_data, language='zh-CN')
    print(f'è¯†åˆ«ç»“æœ: {text}')
    """)

async def example_tts():
    """TTSä½¿ç”¨ç¤ºä¾‹"""
    print("\n=== TTSä½¿ç”¨ç¤ºä¾‹ ===")
    
    # åˆ›å»ºé…ç½®
    voice_config = create_voice_config()
    tts_service = EnhancedTTSService(voice_config)
    
    print(f"ä½¿ç”¨TTSæä¾›å•†: {voice_config.primary_tts_provider.value}")
    
    # æµ‹è¯•æ–‡æœ¬
    text = "ä½ å¥½ï¼Œæ¬¢è¿ä½¿ç”¨è¯­éŸ³åŠ©æ‰‹ï¼ä»Šå¤©å¤©æ°”ä¸é”™ã€‚"
    print(f"åˆæˆæ–‡æœ¬: {text}")
    
    try:
        # åˆæˆè¯­éŸ³
        print("å¼€å§‹è¯­éŸ³åˆæˆ...")
        audio_data = await tts_service.synthesize(text)
        
        if audio_data:
            print(f"âœ… åˆæˆæˆåŠŸï¼ŒéŸ³é¢‘å¤§å°: {len(audio_data)} bytes")
            
            # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
            output_file = "example_output.mp3"
            with open(output_file, "wb") as f:
                f.write(audio_data)
            print(f"éŸ³é¢‘å·²ä¿å­˜åˆ°: {output_file}")
            
        else:
            print("âŒ åˆæˆå¤±è´¥")
            
    except Exception as e:
        print(f"âŒ TTSé”™è¯¯: {e}")

async def example_streaming_tts():
    """æµå¼TTSä½¿ç”¨ç¤ºä¾‹"""
    print("\n=== æµå¼TTSä½¿ç”¨ç¤ºä¾‹ ===")
    
    # åˆ›å»ºé…ç½®
    voice_config = create_voice_config()
    tts_service = EnhancedTTSService(voice_config)
    
    text = "è¿™æ˜¯ä¸€ä¸ªæµå¼è¯­éŸ³åˆæˆçš„ç¤ºä¾‹ã€‚æˆ‘ä»¬å°†æ–‡æœ¬åˆ†å—å¤„ç†ï¼Œå®ç°ä½å»¶è¿Ÿçš„è¯­éŸ³è¾“å‡ºã€‚"
    print(f"åˆæˆæ–‡æœ¬: {text}")
    
    try:
        print("å¼€å§‹æµå¼è¯­éŸ³åˆæˆ...")
        chunks = []
        chunk_count = 0
        
        async for chunk in tts_service.synthesize_streaming(text):
            if chunk:
                chunks.append(chunk)
                chunk_count += 1
                print(f"æ”¶åˆ°éŸ³é¢‘å— {chunk_count}: {len(chunk)} bytes")
        
        if chunks:
            # åˆå¹¶æ‰€æœ‰éŸ³é¢‘å—
            total_audio = b''.join(chunks)
            print(f"âœ… æµå¼åˆæˆå®Œæˆï¼Œæ€»å…± {chunk_count} ä¸ªå—ï¼Œæ€»å¤§å°: {len(total_audio)} bytes")
            
            # ä¿å­˜åˆå¹¶çš„éŸ³é¢‘
            output_file = "example_streaming_output.mp3"
            with open(output_file, "wb") as f:
                f.write(total_audio)
            print(f"åˆå¹¶éŸ³é¢‘å·²ä¿å­˜åˆ°: {output_file}")
            
        else:
            print("âŒ æµå¼åˆæˆå¤±è´¥")
            
    except Exception as e:
        print(f"âŒ æµå¼TTSé”™è¯¯: {e}")

async def example_provider_fallback():
    """æä¾›å•†é™çº§ç¤ºä¾‹"""
    print("\n=== æä¾›å•†é™çº§ç¤ºä¾‹ ===")
    
    # åˆ›å»ºé…ç½®ï¼Œæ•…æ„è®¾ç½®ä¸€ä¸ªä¸å­˜åœ¨çš„ä¸»è¦æä¾›å•†æ¥æµ‹è¯•é™çº§
    voice_config = create_voice_config()
    
    # æ˜¾ç¤ºé…ç½®çš„æä¾›å•†
    print(f"ä¸»è¦TTSæä¾›å•†: {voice_config.primary_tts_provider.value}")
    print(f"é™çº§TTSæä¾›å•†: {[p.value for p in voice_config.fallback_tts_providers]}")
    
    tts_service = EnhancedTTSService(voice_config)
    
    text = "æµ‹è¯•æä¾›å•†é™çº§åŠŸèƒ½ã€‚"
    
    try:
        print("æµ‹è¯•æä¾›å•†é™çº§...")
        audio_data = await tts_service.synthesize(text)
        
        if audio_data:
            print("âœ… åˆæˆæˆåŠŸï¼ˆå¯èƒ½ä½¿ç”¨äº†é™çº§æä¾›å•†ï¼‰")
            
            # æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
            stats = tts_service.get_stats()
            print(f"ç»Ÿè®¡ä¿¡æ¯: {stats}")
            
            if stats['fallback_usage'] > 0:
                print("ğŸ”„ ä½¿ç”¨äº†é™çº§æä¾›å•†")
            else:
                print("âœ¨ ä½¿ç”¨äº†ä¸»è¦æä¾›å•†")
                
        else:
            print("âŒ æ‰€æœ‰æä¾›å•†éƒ½å¤±è´¥äº†")
            
    except Exception as e:
        print(f"âŒ é™çº§æµ‹è¯•é”™è¯¯: {e}")

def show_configuration_guide():
    """æ˜¾ç¤ºé…ç½®æŒ‡å—"""
    print("\n=== é…ç½®æŒ‡å— ===")
    
    print("è¦ä½¿ç”¨è¯­éŸ³æœåŠ¡ï¼Œè¯·é…ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡ï¼š")
    print()
    
    print("1. OpenAI (æ¨èç”¨äºASR):")
    print("   export OPENAI_API_KEY='your-openai-api-key'")
    print("   export OPENAI_BASE_URL='https://api.openai.com/v1'  # å¯é€‰")
    print()
    
    print("2. Azure Speech (æ¨èç”¨äºç”Ÿäº§ç¯å¢ƒ):")
    print("   export AZURE_SPEECH_KEY='your-azure-speech-key'")
    print("   export AZURE_SPEECH_REGION='eastus'  # æˆ–å…¶ä»–åŒºåŸŸ")
    print()
    
    print("3. å…è´¹é€‰é¡¹:")
    print("   - Edge TTS: æ— éœ€é…ç½®ï¼Œè‡ªåŠ¨å¯ç”¨ï¼ˆä»…TTSï¼‰")
    print("   - æœ¬åœ°ASR: æ— éœ€é…ç½®ï¼Œä½¿ç”¨Google Web Speech APIï¼ˆæœ‰é™åˆ¶ï¼‰")
    print()
    
    print("4. å¯é€‰é…ç½®:")
    print("   export VOICE_ENABLE_VAD='true'        # å¯ç”¨è¯­éŸ³æ´»åŠ¨æ£€æµ‹")
    print("   export VOICE_ENABLE_CACHE='true'      # å¯ç”¨TTSç¼“å­˜")
    print("   export VOICE_DEFAULT_LANGUAGE='zh-CN' # é»˜è®¤è¯­è¨€")
    print()

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤ è¯­éŸ³æœåŠ¡ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)
    
    # æ˜¾ç¤ºæä¾›å•†çŠ¶æ€
    status = get_voice_provider_status()
    print("å½“å‰æä¾›å•†çŠ¶æ€:")
    for provider, info in status['providers'].items():
        if info['available']:
            print(f"âœ… {provider.upper()}")
        else:
            print(f"âŒ {provider.upper()}: {info.get('reason', 'Unknown')}")
    
    # å¦‚æœæ²¡æœ‰å¯ç”¨çš„å•†ä¸šæä¾›å•†ï¼Œæ˜¾ç¤ºé…ç½®æŒ‡å—
    has_commercial = any(
        info['available'] and provider in ['openai', 'azure'] 
        for provider, info in status['providers'].items()
    )
    
    if not has_commercial:
        show_configuration_guide()
        print("\næ³¨æ„: å½“å‰åªæœ‰å…è´¹æä¾›å•†å¯ç”¨ï¼ŒåŠŸèƒ½å¯èƒ½å—é™ã€‚")
        print("å»ºè®®é…ç½®è‡³å°‘ä¸€ä¸ªå•†ä¸šæä¾›å•†ä»¥è·å¾—æ›´å¥½çš„ä½“éªŒã€‚")
    
    # è¿è¡Œç¤ºä¾‹
    await example_asr()
    await example_tts()
    await example_streaming_tts()
    await example_provider_fallback()
    
    print("\n" + "=" * 50)
    print("âœ… ç¤ºä¾‹è¿è¡Œå®Œæˆ")
    
    # æ¸…ç†ç”Ÿæˆçš„æ–‡ä»¶
    for file in ["example_output.mp3", "example_streaming_output.mp3"]:
        if os.path.exists(file):
            print(f"ç”Ÿæˆçš„æ–‡ä»¶: {file}")

if __name__ == "__main__":
    asyncio.run(main())
