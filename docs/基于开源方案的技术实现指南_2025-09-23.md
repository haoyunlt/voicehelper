# VoiceHelper åŸºäºå¼€æºæ–¹æ¡ˆçš„æŠ€æœ¯å®ç°æŒ‡å—

> åŸºäºä¸šç•Œæœ€æ–°å¼€æºè¯­éŸ³åŠ©æ‰‹æŠ€æœ¯æ ˆåˆ†æ  
> å‚è€ƒé¡¹ç›®ï¼šOpenAI Whisperã€Rasaã€Mycroftã€Mozilla DeepSpeech  
> æ›´æ–°æ—¥æœŸï¼š2025å¹´9æœˆ23æ—¥

## ğŸ¯ æŠ€æœ¯å€ºåŠ¡ä¸æ ¸å¿ƒé—®é¢˜åˆ†æ

### ğŸ“Š å½“å‰é¡¹ç›®çŠ¶æ€å¯¹æ¯”åˆ†æ

| åŠŸèƒ½æ¨¡å— | å£°ç§°çŠ¶æ€ | å®é™…çŠ¶æ€ | ä¸šç•Œæ ‡å‡† | å·®è·è¯„ä¼° |
|---------|---------|---------|---------|---------|
| å®æ—¶è¯­éŸ³å¤„ç† | 95%å®Œæˆ | 30%å®Œæˆ | OpenAI Whisperçº§åˆ« | ä¸¥é‡æ»å |
| å¯¹è¯ç®¡ç† | 90%å®Œæˆ | 40%å®Œæˆ | Rasa Coreçº§åˆ« | åŠŸèƒ½ç¼ºå¤± |
| å¤šæ¨¡æ€ç†è§£ | 100%å®Œæˆ | 20%å®Œæˆ | GPT-4Vçº§åˆ« | åŸºç¡€ç¼ºå¤± |
| å®æ—¶é€šä¿¡ | 95%å®Œæˆ | 50%å®Œæˆ | WebRTCæ ‡å‡† | æ¶æ„ä¸å®Œæ•´ |
| ç›‘æ§è§‚æµ‹ | 95%å®Œæˆ | 20%å®Œæˆ | Prometheusç”Ÿæ€ | ç³»ç»Ÿç¼ºå¤± |

---

## ğŸš¨ å…³é”®æŠ€æœ¯å€ºåŠ¡æ¸…å•

### 1. è¯­éŸ³å¤„ç†ç³»ç»Ÿ - ä¸¥é‡ç¼ºå¤±
**é—®é¢˜æè¿°**ï¼š
- WebSocketè¯­éŸ³å¤„ç†å™¨æ–‡ä»¶å®Œå…¨ç¼ºå¤±
- ASR/TTSé›†æˆä¸å®Œæ•´ï¼Œç¼ºä¹å®æ—¶æµå¤„ç†
- éŸ³é¢‘ç¼–è§£ç å’Œæ ¼å¼è½¬æ¢åŠŸèƒ½ç¼ºå¤±
- VADï¼ˆè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼‰åŠŸèƒ½æœªå®ç°

**ä¸šç•Œå¯¹æ ‡**ï¼š
- **OpenAI Whisper**: å®æ—¶è¯­éŸ³è¯†åˆ«ï¼Œæ”¯æŒå¤šè¯­è¨€
- **Mozilla DeepSpeech**: å¼€æºè¯­éŸ³è¯†åˆ«å¼•æ“
- **WebRTC**: å®æ—¶éŸ³è§†é¢‘é€šä¿¡æ ‡å‡†

### 2. AIå¯¹è¯ç®¡ç†ç³»ç»Ÿ - åŠŸèƒ½ç®€åŒ–
**é—®é¢˜æè¿°**ï¼š
- LangChain/LangGraphä¾èµ–è¢«ç§»é™¤
- å¯¹è¯çŠ¶æ€ç®¡ç†ä¸å®Œæ•´
- æ„å›¾è¯†åˆ«å’Œå®ä½“æŠ½å–åŠŸèƒ½ç¼ºå¤±
- å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†ç¼ºå¤±

**ä¸šç•Œå¯¹æ ‡**ï¼š
- **Rasa**: å¼€æºå¯¹è¯AIæ¡†æ¶
- **Microsoft Bot Framework**: ä¼ä¸šçº§å¯¹è¯ç®¡ç†
- **Dialogflow**: Googleå¯¹è¯AIå¹³å°

### 3. ç›‘æ§è§‚æµ‹ç³»ç»Ÿ - å®Œå…¨ç¼ºå¤±
**é—®é¢˜æè¿°**ï¼š
- PrometheusæŒ‡æ ‡ç³»ç»Ÿè¢«åˆ é™¤
- é“¾è·¯è¿½è¸ªåŠŸèƒ½ç¼ºå¤±
- æœåŠ¡å¥åº·æ£€æŸ¥ä¸å®Œæ•´
- æ€§èƒ½æŒ‡æ ‡æ”¶é›†ç¼ºå¤±

**ä¸šç•Œå¯¹æ ‡**ï¼š
- **Prometheus + Grafana**: ç›‘æ§å¯è§†åŒ–æ ‡å‡†
- **Jaeger**: åˆ†å¸ƒå¼é“¾è·¯è¿½è¸ª
- **OpenTelemetry**: å¯è§‚æµ‹æ€§æ ‡å‡†

---

## ğŸ› ï¸ åŸºäºå¼€æºæ–¹æ¡ˆçš„æŠ€æœ¯å®ç°

### 1. å®æ—¶è¯­éŸ³å¤„ç†ç³»ç»Ÿé‡å»º

#### 1.1 åŸºäºOpenAI Whisperçš„ASRæœåŠ¡

```python
# algo/core/whisper_asr.py
import asyncio
import torch
import whisper
import numpy as np
from typing import AsyncGenerator, Optional
import webrtcvad
import collections
import logging

logger = logging.getLogger(__name__)

class WhisperASRService:
    """åŸºäºOpenAI Whisperçš„å®æ—¶ASRæœåŠ¡"""
    
    def __init__(self, model_size: str = "base", language: str = "zh"):
        self.model = whisper.load_model(model_size)
        self.language = language
        self.vad = webrtcvad.Vad(2)  # è¯­éŸ³æ´»åŠ¨æ£€æµ‹
        self.sample_rate = 16000
        self.frame_duration = 30  # ms
        self.frame_size = int(self.sample_rate * self.frame_duration / 1000)
        
        # éŸ³é¢‘ç¼“å†²åŒº
        self.audio_buffer = collections.deque(maxlen=100)
        self.is_speaking = False
        self.silence_frames = 0
        self.speech_frames = 0
        
    async def process_audio_stream(self, audio_chunk: bytes) -> AsyncGenerator[dict, None]:
        """å¤„ç†å®æ—¶éŸ³é¢‘æµ"""
        try:
            # è½¬æ¢éŸ³é¢‘æ ¼å¼
            audio_data = np.frombuffer(audio_chunk, dtype=np.int16)
            
            # VADæ£€æµ‹
            is_speech = self._detect_speech(audio_chunk)
            
            if is_speech:
                self.speech_frames += 1
                self.silence_frames = 0
                self.audio_buffer.extend(audio_data)
                
                # å¼€å§‹è¯´è¯
                if not self.is_speaking:
                    self.is_speaking = True
                    yield {"type": "speech_start", "timestamp": asyncio.get_event_loop().time()}
                    
            else:
                self.silence_frames += 1
                
                # æ£€æµ‹è¯´è¯ç»“æŸ
                if self.is_speaking and self.silence_frames > 10:  # 300msé™éŸ³
                    self.is_speaking = False
                    
                    # æ‰§è¡Œè¯­éŸ³è¯†åˆ«
                    if len(self.audio_buffer) > 0:
                        transcript = await self._transcribe_audio()
                        yield {
                            "type": "speech_end",
                            "transcript": transcript,
                            "confidence": 0.95,  # Whisper doesn't provide confidence
                            "timestamp": asyncio.get_event_loop().time()
                        }
                        
                    self.audio_buffer.clear()
                    self.speech_frames = 0
                    
        except Exception as e:
            logger.error(f"ASRå¤„ç†é”™è¯¯: {e}")
            yield {"type": "error", "message": str(e)}
    
    def _detect_speech(self, audio_chunk: bytes) -> bool:
        """è¯­éŸ³æ´»åŠ¨æ£€æµ‹"""
        try:
            return self.vad.is_speech(audio_chunk, self.sample_rate)
        except:
            return False
    
    async def _transcribe_audio(self) -> str:
        """è½¬å½•éŸ³é¢‘"""
        try:
            # åˆå¹¶éŸ³é¢‘ç¼“å†²åŒº
            audio_array = np.array(list(self.audio_buffer), dtype=np.float32)
            audio_array = audio_array / 32768.0  # å½’ä¸€åŒ–åˆ°[-1, 1]
            
            # ä½¿ç”¨Whisperè¿›è¡Œè½¬å½•
            result = self.model.transcribe(
                audio_array,
                language=self.language,
                task="transcribe",
                fp16=torch.cuda.is_available()
            )
            
            return result["text"].strip()
            
        except Exception as e:
            logger.error(f"éŸ³é¢‘è½¬å½•é”™è¯¯: {e}")
            return ""

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    asr = WhisperASRService(model_size="base", language="zh")
    
    # æ¨¡æ‹ŸéŸ³é¢‘æµå¤„ç†
    async for result in asr.process_audio_stream(audio_chunk):
        print(f"ASRç»“æœ: {result}")

if __name__ == "__main__":
    asyncio.run(main())
```

#### 1.2 åŸºäºEdge-TTSçš„è¯­éŸ³åˆæˆæœåŠ¡

```python
# algo/core/edge_tts_service.py
import asyncio
import edge_tts
import io
import logging
from typing import AsyncGenerator, Optional

logger = logging.getLogger(__name__)

class EdgeTTSService:
    """åŸºäºEdge-TTSçš„è¯­éŸ³åˆæˆæœåŠ¡"""
    
    def __init__(self, voice: str = "zh-CN-XiaoxiaoNeural", rate: str = "+0%"):
        self.voice = voice
        self.rate = rate
        self.pitch = "+0Hz"
        
    async def synthesize_stream(self, text: str) -> AsyncGenerator[bytes, None]:
        """æµå¼è¯­éŸ³åˆæˆ"""
        try:
            communicate = edge_tts.Communicate(
                text=text,
                voice=self.voice,
                rate=self.rate,
                pitch=self.pitch
            )
            
            async for chunk in communicate.stream():
                if chunk["type"] == "audio":
                    yield chunk["data"]
                elif chunk["type"] == "WordBoundary":
                    # å¯ä»¥ç”¨äºå®ç°å­—çº§åˆ«çš„åŒæ­¥
                    logger.debug(f"Word boundary: {chunk}")
                    
        except Exception as e:
            logger.error(f"TTSåˆæˆé”™è¯¯: {e}")
            raise
    
    async def synthesize_complete(self, text: str) -> bytes:
        """å®Œæ•´è¯­éŸ³åˆæˆ"""
        audio_data = b""
        async for chunk in self.synthesize_stream(text):
            audio_data += chunk
        return audio_data
    
    @staticmethod
    async def get_available_voices():
        """è·å–å¯ç”¨è¯­éŸ³åˆ—è¡¨"""
        voices = await edge_tts.list_voices()
        return [
            {
                "name": voice["Name"],
                "display_name": voice["DisplayName"],
                "locale": voice["Locale"],
                "gender": voice["Gender"]
            }
            for voice in voices
        ]

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    tts = EdgeTTSService(voice="zh-CN-XiaoxiaoNeural")
    
    # æµå¼åˆæˆ
    audio_chunks = []
    async for chunk in tts.synthesize_stream("ä½ å¥½ï¼Œæˆ‘æ˜¯VoiceHelperè¯­éŸ³åŠ©æ‰‹"):
        audio_chunks.append(chunk)
    
    # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
    with open("output.mp3", "wb") as f:
        f.write(b"".join(audio_chunks))

if __name__ == "__main__":
    asyncio.run(main())
```

#### 1.3 WebSocketè¯­éŸ³å¤„ç†å™¨é‡å»º

```go
// backend/internal/handlers/realtime_voice.go
package handlers

import (
    "context"
    "encoding/json"
    "fmt"
    "log"
    "net/http"
    "sync"
    "time"

    "github.com/gin-gonic/gin"
    "github.com/gorilla/websocket"
    "github.com/google/uuid"
)

type RealtimeVoiceHandler struct {
    upgrader    websocket.Upgrader
    sessions    map[string]*VoiceSession
    sessionsMux sync.RWMutex
    asrClient   ASRClient
    ttsClient   TTSClient
}

type VoiceSession struct {
    ID           string
    Connection   *websocket.Conn
    Context      context.Context
    Cancel       context.CancelFunc
    AudioBuffer  []byte
    IsRecording  bool
    LastActivity time.Time
    UserID       string
    TenantID     string
}

type VoiceMessage struct {
    Type      string      `json:"type"`
    SessionID string      `json:"session_id,omitempty"`
    Data      interface{} `json:"data,omitempty"`
    Timestamp int64       `json:"timestamp"`
}

type AudioData struct {
    Chunk    string `json:"chunk"`     // base64ç¼–ç çš„éŸ³é¢‘æ•°æ®
    Format   string `json:"format"`    // éŸ³é¢‘æ ¼å¼: "pcm16", "opus", "mp3"
    SampleRate int  `json:"sample_rate"` // é‡‡æ ·ç‡
    Channels int    `json:"channels"`   // å£°é“æ•°
    IsFinal  bool   `json:"is_final"`  // æ˜¯å¦ä¸ºæœ€åä¸€å—
}

type ASRResult struct {
    Text       string  `json:"text"`
    Confidence float64 `json:"confidence"`
    IsFinal    bool    `json:"is_final"`
    Language   string  `json:"language"`
}

func NewRealtimeVoiceHandler(asrClient ASRClient, ttsClient TTSClient) *RealtimeVoiceHandler {
    return &RealtimeVoiceHandler{
        upgrader: websocket.Upgrader{
            CheckOrigin: func(r *http.Request) bool {
                return true // ç”Ÿäº§ç¯å¢ƒéœ€è¦ä¸¥æ ¼æ£€æŸ¥
            },
            ReadBufferSize:  4096,
            WriteBufferSize: 4096,
        },
        sessions:  make(map[string]*VoiceSession),
        asrClient: asrClient,
        ttsClient: ttsClient,
    }
}

func (h *RealtimeVoiceHandler) HandleWebSocket(c *gin.Context) {
    conn, err := h.upgrader.Upgrade(c.Writer, c.Request, nil)
    if err != nil {
        log.Printf("WebSocketå‡çº§å¤±è´¥: %v", err)
        return
    }
    defer conn.Close()

    // åˆ›å»ºä¼šè¯
    sessionID := uuid.New().String()
    ctx, cancel := context.WithCancel(context.Background())
    
    session := &VoiceSession{
        ID:           sessionID,
        Connection:   conn,
        Context:      ctx,
        Cancel:       cancel,
        AudioBuffer:  make([]byte, 0),
        IsRecording:  false,
        LastActivity: time.Now(),
        UserID:       c.GetString("user_id"),
        TenantID:     c.GetString("tenant_id"),
    }

    h.sessionsMux.Lock()
    h.sessions[sessionID] = session
    h.sessionsMux.Unlock()

    // å‘é€ä¼šè¯åˆ›å»ºç¡®è®¤
    h.sendMessage(session, VoiceMessage{
        Type:      "session_created",
        SessionID: sessionID,
        Data: map[string]interface{}{
            "session_id": sessionID,
            "status":     "ready",
        },
        Timestamp: time.Now().UnixMilli(),
    })

    // å¯åŠ¨æ¶ˆæ¯å¤„ç†å¾ªç¯
    go h.handleMessages(session)
    
    // å¯åŠ¨ä¼šè¯æ¸…ç†å®šæ—¶å™¨
    go h.sessionCleanup(session)
    
    // ç­‰å¾…ä¼šè¯ç»“æŸ
    <-ctx.Done()
    
    // æ¸…ç†ä¼šè¯
    h.sessionsMux.Lock()
    delete(h.sessions, sessionID)
    h.sessionsMux.Unlock()
}

func (h *RealtimeVoiceHandler) handleMessages(session *VoiceSession) {
    defer session.Cancel()
    
    for {
        select {
        case <-session.Context.Done():
            return
        default:
            var msg VoiceMessage
            err := session.Connection.ReadJSON(&msg)
            if err != nil {
                if websocket.IsUnexpectedCloseError(err, websocket.CloseGoingAway, websocket.CloseAbnormalClosure) {
                    log.Printf("WebSocketè¯»å–é”™è¯¯: %v", err)
                }
                return
            }
            
            session.LastActivity = time.Now()
            
            switch msg.Type {
            case "start_recording":
                h.handleStartRecording(session, msg)
            case "audio_chunk":
                h.handleAudioChunk(session, msg)
            case "stop_recording":
                h.handleStopRecording(session, msg)
            case "ping":
                h.handlePing(session, msg)
            default:
                h.sendError(session, "unknown_message_type", fmt.Sprintf("æœªçŸ¥æ¶ˆæ¯ç±»å‹: %s", msg.Type))
            }
        }
    }
}

func (h *RealtimeVoiceHandler) handleStartRecording(session *VoiceSession, msg VoiceMessage) {
    if session.IsRecording {
        h.sendError(session, "already_recording", "ä¼šè¯å·²åœ¨å½•éŸ³ä¸­")
        return
    }
    
    session.IsRecording = true
    session.AudioBuffer = session.AudioBuffer[:0] // æ¸…ç©ºç¼“å†²åŒº
    
    h.sendMessage(session, VoiceMessage{
        Type:      "recording_started",
        SessionID: session.ID,
        Data: map[string]interface{}{
            "status": "recording",
        },
        Timestamp: time.Now().UnixMilli(),
    })
    
    log.Printf("ä¼šè¯ %s å¼€å§‹å½•éŸ³", session.ID)
}

func (h *RealtimeVoiceHandler) handleAudioChunk(session *VoiceSession, msg VoiceMessage) {
    if !session.IsRecording {
        h.sendError(session, "not_recording", "ä¼šè¯æœªåœ¨å½•éŸ³çŠ¶æ€")
        return
    }
    
    // è§£æéŸ³é¢‘æ•°æ®
    audioDataMap, ok := msg.Data.(map[string]interface{})
    if !ok {
        h.sendError(session, "invalid_audio_data", "æ— æ•ˆçš„éŸ³é¢‘æ•°æ®æ ¼å¼")
        return
    }
    
    var audioData AudioData
    audioDataBytes, _ := json.Marshal(audioDataMap)
    if err := json.Unmarshal(audioDataBytes, &audioData); err != nil {
        h.sendError(session, "parse_error", fmt.Sprintf("éŸ³é¢‘æ•°æ®è§£æå¤±è´¥: %v", err))
        return
    }
    
    // å¤„ç†éŸ³é¢‘æ•°æ®
    go h.processAudioChunk(session, audioData)
}

func (h *RealtimeVoiceHandler) processAudioChunk(session *VoiceSession, audioData AudioData) {
    // è§£ç base64éŸ³é¢‘æ•°æ®
    // è¿™é‡Œéœ€è¦å®ç°éŸ³é¢‘è§£ç å’ŒASRå¤„ç†
    // è°ƒç”¨ASRæœåŠ¡è¿›è¡Œå®æ—¶è¯†åˆ«
    
    // æ¨¡æ‹ŸASRç»“æœ
    asrResult := ASRResult{
        Text:       "è¿™æ˜¯è¯†åˆ«çš„æ–‡æœ¬",
        Confidence: 0.95,
        IsFinal:    audioData.IsFinal,
        Language:   "zh-CN",
    }
    
    h.sendMessage(session, VoiceMessage{
        Type:      "asr_result",
        SessionID: session.ID,
        Data:      asrResult,
        Timestamp: time.Now().UnixMilli(),
    })
}

func (h *RealtimeVoiceHandler) handleStopRecording(session *VoiceSession, msg VoiceMessage) {
    if !session.IsRecording {
        h.sendError(session, "not_recording", "ä¼šè¯æœªåœ¨å½•éŸ³çŠ¶æ€")
        return
    }
    
    session.IsRecording = false
    
    h.sendMessage(session, VoiceMessage{
        Type:      "recording_stopped",
        SessionID: session.ID,
        Data: map[string]interface{}{
            "status": "stopped",
        },
        Timestamp: time.Now().UnixMilli(),
    })
    
    log.Printf("ä¼šè¯ %s åœæ­¢å½•éŸ³", session.ID)
}

func (h *RealtimeVoiceHandler) handlePing(session *VoiceSession, msg VoiceMessage) {
    h.sendMessage(session, VoiceMessage{
        Type:      "pong",
        SessionID: session.ID,
        Timestamp: time.Now().UnixMilli(),
    })
}

func (h *RealtimeVoiceHandler) sendMessage(session *VoiceSession, msg VoiceMessage) {
    if err := session.Connection.WriteJSON(msg); err != nil {
        log.Printf("å‘é€æ¶ˆæ¯å¤±è´¥: %v", err)
        session.Cancel()
    }
}

func (h *RealtimeVoiceHandler) sendError(session *VoiceSession, code, message string) {
    h.sendMessage(session, VoiceMessage{
        Type:      "error",
        SessionID: session.ID,
        Data: map[string]interface{}{
            "code":    code,
            "message": message,
        },
        Timestamp: time.Now().UnixMilli(),
    })
}

func (h *RealtimeVoiceHandler) sessionCleanup(session *VoiceSession) {
    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()
    
    for {
        select {
        case <-session.Context.Done():
            return
        case <-ticker.C:
            if time.Since(session.LastActivity) > 5*time.Minute {
                log.Printf("ä¼šè¯ %s è¶…æ—¶ï¼Œè‡ªåŠ¨æ¸…ç†", session.ID)
                session.Cancel()
                return
            }
        }
    }
}

// ASRå’ŒTTSå®¢æˆ·ç«¯æ¥å£
type ASRClient interface {
    Recognize(audioData []byte, config ASRConfig) (*ASRResult, error)
}

type TTSClient interface {
    Synthesize(text string, config TTSConfig) ([]byte, error)
}

type ASRConfig struct {
    Language   string
    SampleRate int
    Format     string
}

type TTSConfig struct {
    Voice      string
    Language   string
    SampleRate int
}
```

### 2. åŸºäºRasaçš„å¯¹è¯ç®¡ç†ç³»ç»Ÿ

#### 2.1 Rasaå¯¹è¯ç®¡ç†é›†æˆ

```python
# algo/core/rasa_dialogue.py
import asyncio
import aiohttp
import logging
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
import json

logger = logging.getLogger(__name__)

@dataclass
class DialogueState:
    """å¯¹è¯çŠ¶æ€"""
    user_id: str
    session_id: str
    current_intent: Optional[str] = None
    entities: Dict[str, Any] = None
    context: Dict[str, Any] = None
    history: List[Dict[str, Any]] = None
    
    def __post_init__(self):
        if self.entities is None:
            self.entities = {}
        if self.context is None:
            self.context = {}
        if self.history is None:
            self.history = []

@dataclass
class DialogueResponse:
    """å¯¹è¯å“åº”"""
    text: str
    intent: str
    confidence: float
    entities: Dict[str, Any]
    actions: List[str]
    context_updates: Dict[str, Any]

class RasaDialogueManager:
    """åŸºäºRasaçš„å¯¹è¯ç®¡ç†å™¨"""
    
    def __init__(self, rasa_server_url: str = "http://localhost:5005"):
        self.rasa_server_url = rasa_server_url
        self.session = None
        self.dialogue_states: Dict[str, DialogueState] = {}
        
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def process_message(
        self, 
        user_id: str, 
        session_id: str, 
        message: str,
        metadata: Optional[Dict[str, Any]] = None
    ) -> DialogueResponse:
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯"""
        try:
            # è·å–æˆ–åˆ›å»ºå¯¹è¯çŠ¶æ€
            state_key = f"{user_id}:{session_id}"
            if state_key not in self.dialogue_states:
                self.dialogue_states[state_key] = DialogueState(
                    user_id=user_id,
                    session_id=session_id
                )
            
            dialogue_state = self.dialogue_states[state_key]
            
            # è°ƒç”¨Rasaè¿›è¡Œæ„å›¾è¯†åˆ«å’Œå®ä½“æŠ½å–
            nlu_result = await self._call_rasa_nlu(message)
            
            # è°ƒç”¨Rasa Coreè¿›è¡Œå¯¹è¯ç®¡ç†
            core_result = await self._call_rasa_core(
                user_id, session_id, message, nlu_result, metadata
            )
            
            # æ›´æ–°å¯¹è¯çŠ¶æ€
            dialogue_state.current_intent = nlu_result.get("intent", {}).get("name")
            dialogue_state.entities.update(
                {entity["entity"]: entity["value"] for entity in nlu_result.get("entities", [])}
            )
            dialogue_state.history.append({
                "user_message": message,
                "bot_response": core_result.get("text", ""),
                "intent": dialogue_state.current_intent,
                "timestamp": asyncio.get_event_loop().time()
            })
            
            # æ„å»ºå“åº”
            response = DialogueResponse(
                text=core_result.get("text", ""),
                intent=dialogue_state.current_intent or "unknown",
                confidence=nlu_result.get("intent", {}).get("confidence", 0.0),
                entities=dialogue_state.entities.copy(),
                actions=[action.get("action") for action in core_result.get("actions", [])],
                context_updates={}
            )
            
            return response
            
        except Exception as e:
            logger.error(f"å¯¹è¯å¤„ç†é”™è¯¯: {e}")
            return DialogueResponse(
                text="æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚",
                intent="error",
                confidence=0.0,
                entities={},
                actions=[],
                context_updates={}
            )
    
    async def _call_rasa_nlu(self, message: str) -> Dict[str, Any]:
        """è°ƒç”¨Rasa NLUè¿›è¡Œæ„å›¾è¯†åˆ«å’Œå®ä½“æŠ½å–"""
        try:
            async with self.session.post(
                f"{self.rasa_server_url}/model/parse",
                json={"text": message}
            ) as response:
                if response.status == 200:
                    return await response.json()
                else:
                    logger.error(f"Rasa NLUè°ƒç”¨å¤±è´¥: {response.status}")
                    return {}
        except Exception as e:
            logger.error(f"Rasa NLUè°ƒç”¨å¼‚å¸¸: {e}")
            return {}
    
    async def _call_rasa_core(
        self, 
        user_id: str, 
        session_id: str, 
        message: str, 
        nlu_result: Dict[str, Any],
        metadata: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """è°ƒç”¨Rasa Coreè¿›è¡Œå¯¹è¯ç®¡ç†"""
        try:
            payload = {
                "sender": f"{user_id}:{session_id}",
                "message": message,
                "metadata": metadata or {}
            }
            
            async with self.session.post(
                f"{self.rasa_server_url}/webhooks/rest/webhook",
                json=payload
            ) as response:
                if response.status == 200:
                    results = await response.json()
                    if results:
                        return results[0]  # è¿”å›ç¬¬ä¸€ä¸ªå“åº”
                    else:
                        return {"text": "æˆ‘ä¸å¤ªæ˜ç™½æ‚¨çš„æ„æ€ï¼Œèƒ½å†è¯´ä¸€éå—ï¼Ÿ"}
                else:
                    logger.error(f"Rasa Coreè°ƒç”¨å¤±è´¥: {response.status}")
                    return {"text": "æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ã€‚"}
        except Exception as e:
            logger.error(f"Rasa Coreè°ƒç”¨å¼‚å¸¸: {e}")
            return {"text": "æœåŠ¡å‡ºç°å¼‚å¸¸ï¼Œè¯·ç¨åå†è¯•ã€‚"}
    
    async def get_dialogue_state(self, user_id: str, session_id: str) -> Optional[DialogueState]:
        """è·å–å¯¹è¯çŠ¶æ€"""
        state_key = f"{user_id}:{session_id}"
        return self.dialogue_states.get(state_key)
    
    async def clear_dialogue_state(self, user_id: str, session_id: str):
        """æ¸…é™¤å¯¹è¯çŠ¶æ€"""
        state_key = f"{user_id}:{session_id}"
        if state_key in self.dialogue_states:
            del self.dialogue_states[state_key]

# Rasaé…ç½®æ–‡ä»¶ç¤ºä¾‹
RASA_CONFIG_YML = """
# config.yml
language: zh

pipeline:
  - name: JiebaTokenizer
  - name: RegexFeaturizer
  - name: LexicalSyntacticFeaturizer
  - name: CountVectorsFeaturizer
  - name: CountVectorsFeaturizer
    analyzer: char_wb
    min_ngram: 1
    max_ngram: 4
  - name: DIETClassifier
    epochs: 100
    constrain_similarities: true
  - name: EntitySynonymMapper
  - name: ResponseSelector
    epochs: 100
    constrain_similarities: true
  - name: FallbackClassifier
    threshold: 0.3
    ambiguity_threshold: 0.1

policies:
  - name: MemoizationPolicy
  - name: RulePolicy
  - name: UnexpecTEDIntentPolicy
    max_history: 5
    epochs: 100
  - name: TEDPolicy
    max_history: 5
    epochs: 100
    constrain_similarities: true
"""

RASA_DOMAIN_YML = """
# domain.yml
version: "3.1"

intents:
  - greet
  - goodbye
  - affirm
  - deny
  - mood_great
  - mood_unhappy
  - bot_challenge
  - ask_weather
  - ask_time
  - play_music
  - set_reminder

entities:
  - city
  - time
  - music_genre
  - reminder_content

slots:
  city:
    type: text
    mappings:
    - type: from_entity
      entity: city
  
  music_genre:
    type: text
    mappings:
    - type: from_entity
      entity: music_genre

responses:
  utter_greet:
  - text: "ä½ å¥½ï¼æˆ‘æ˜¯VoiceHelperï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ï¼"
  
  utter_cheer_up:
  - text: "å¸Œæœ›æˆ‘èƒ½è®©æ‚¨å¼€å¿ƒèµ·æ¥ï¼"
  
  utter_did_that_help:
  - text: "è¿™æ ·æœ‰å¸®åŠ©å—ï¼Ÿ"
  
  utter_happy:
  - text: "å¤ªå¥½äº†ï¼"
  
  utter_goodbye:
  - text: "å†è§ï¼ç¥æ‚¨æœ‰ç¾å¥½çš„ä¸€å¤©ï¼"
  
  utter_iamabot:
  - text: "æˆ‘æ˜¯VoiceHelper AIåŠ©æ‰‹ï¼Œç”±äººå·¥æ™ºèƒ½é©±åŠ¨ã€‚"

actions:
  - action_weather_query
  - action_play_music
  - action_set_reminder

session_config:
  session_expiration_time: 60
  carry_over_slots_to_new_session: true
"""

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    async with RasaDialogueManager("http://localhost:5005") as dialogue_manager:
        response = await dialogue_manager.process_message(
            user_id="user123",
            session_id="session456",
            message="ä½ å¥½ï¼Œä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"
        )
        
        print(f"Botå›å¤: {response.text}")
        print(f"è¯†åˆ«æ„å›¾: {response.intent}")
        print(f"ç½®ä¿¡åº¦: {response.confidence}")
        print(f"å®ä½“: {response.entities}")

if __name__ == "__main__":
    asyncio.run(main())
```

### 3. Prometheusç›‘æ§ç³»ç»Ÿé‡å»º

#### 3.1 ç»Ÿä¸€æŒ‡æ ‡æ”¶é›†ç³»ç»Ÿ

```go
// backend/pkg/metrics/unified_metrics.go
package metrics

import (
    "sync"
    "time"
    
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

var (
    once sync.Once
    metricsRegistry *MetricsRegistry
)

type MetricsRegistry struct {
    // HTTPè¯·æ±‚æŒ‡æ ‡
    HTTPRequestsTotal *prometheus.CounterVec
    HTTPRequestDuration *prometheus.HistogramVec
    HTTPRequestSize *prometheus.HistogramVec
    HTTPResponseSize *prometheus.HistogramVec
    
    // WebSocketè¿æ¥æŒ‡æ ‡
    WSConnectionsActive prometheus.Gauge
    WSConnectionsTotal *prometheus.CounterVec
    WSMessagesSent *prometheus.CounterVec
    WSMessagesReceived *prometheus.CounterVec
    
    // è¯­éŸ³å¤„ç†æŒ‡æ ‡
    VoiceSessionsActive prometheus.Gauge
    VoiceProcessingDuration *prometheus.HistogramVec
    ASRRequestsTotal *prometheus.CounterVec
    ASRLatency *prometheus.HistogramVec
    TTSRequestsTotal *prometheus.CounterVec
    TTSLatency *prometheus.HistogramVec
    
    // AIæœåŠ¡æŒ‡æ ‡
    LLMRequestsTotal *prometheus.CounterVec
    LLMTokensUsed *prometheus.CounterVec
    LLMLatency *prometheus.HistogramVec
    RAGQueryTotal *prometheus.CounterVec
    RAGLatency *prometheus.HistogramVec
    
    // ç³»ç»Ÿèµ„æºæŒ‡æ ‡
    MemoryUsage prometheus.Gauge
    CPUUsage prometheus.Gauge
    DiskUsage prometheus.Gauge
    
    // ä¸šåŠ¡æŒ‡æ ‡
    ActiveUsers prometheus.Gauge
    TotalConversations *prometheus.CounterVec
    UserSatisfaction *prometheus.HistogramVec
}

func GetMetricsRegistry() *MetricsRegistry {
    once.Do(func() {
        metricsRegistry = &MetricsRegistry{
            // HTTPè¯·æ±‚æŒ‡æ ‡
            HTTPRequestsTotal: promauto.NewCounterVec(
                prometheus.CounterOpts{
                    Name: "voicehelper_http_requests_total",
                    Help: "Total number of HTTP requests",
                },
                []string{"method", "endpoint", "status_code", "tenant_id"},
            ),
            
            HTTPRequestDuration: promauto.NewHistogramVec(
                prometheus.HistogramOpts{
                    Name: "voicehelper_http_request_duration_seconds",
                    Help: "HTTP request duration in seconds",
                    Buckets: []float64{0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10},
                },
                []string{"method", "endpoint", "tenant_id"},
            ),
            
            HTTPRequestSize: promauto.NewHistogramVec(
                prometheus.HistogramOpts{
                    Name: "voicehelper_http_request_size_bytes",
                    Help: "HTTP request size in bytes",
                    Buckets: prometheus.ExponentialBuckets(100, 10, 8),
                },
                []string{"method", "endpoint"},
            ),
            
            HTTPResponseSize: promauto.NewHistogramVec(
                prometheus.HistogramOpts{
                    Name: "voicehelper_http_response_size_bytes",
                    Help: "HTTP response size in bytes",
                    Buckets: prometheus.ExponentialBuckets(100, 10, 8),
                },
                []string{"method", "endpoint"},
            ),
            
            // WebSocketè¿æ¥æŒ‡æ ‡
            WSConnectionsActive: promauto.NewGauge(
                prometheus.GaugeOpts{
                    Name: "voicehelper_ws_connections_active",
                    Help: "Number of active WebSocket connections",
                },
            ),
            
            WSConnectionsTotal: promauto.NewCounterVec(
                prometheus.CounterOpts{
                    Name: "voicehelper_ws_connections_total",
                    Help: "Total number of WebSocket connections",
                },
                []string{"type", "tenant_id"},
            ),
            
            WSMessagesSent: promauto.NewCounterVec(
                prometheus.CounterOpts{
                    Name: "voicehelper_ws_messages_sent_total",
                    Help: "Total number of WebSocket messages sent",
                },
                []string{"type", "session_id"},
            ),
            
            WSMessagesReceived: promauto.NewCounterVec(
                prometheus.CounterOpts{
                    Name: "voicehelper_ws_messages_received_total",
                    Help: "Total number of WebSocket messages received",
                },
                []string{"type", "session_id"},
            ),
            
            // è¯­éŸ³å¤„ç†æŒ‡æ ‡
            VoiceSessionsActive: promauto.NewGauge(
                prometheus.GaugeOpts{
                    Name: "voicehelper_voice_sessions_active",
                    Help: "Number of active voice sessions",
                },
            ),
            
            VoiceProcessingDuration: promauto.NewHistogramVec(
                prometheus.HistogramOpts{
                    Name: "voicehelper_voice_processing_duration_seconds",
                    Help: "Voice processing duration in seconds",
                    Buckets: []float64{0.1, 0.25, 0.5, 1, 2, 5, 10, 30},
                },
                []string{"type", "model", "language"},
            ),
            
            ASRRequestsTotal: promauto.NewCounterVec(
                prometheus.CounterOpts{
                    Name: "voicehelper_asr_requests_total",
                    Help: "Total number of ASR requests",
                },
                []string{"model", "language", "status"},
            ),
            
            ASRLatency: promauto.NewHistogramVec(
                prometheus.HistogramOpts{
                    Name: "voicehelper_asr_latency_seconds",
                    Help: "ASR processing latency in seconds",
                    Buckets: []float64{0.1, 0.2, 0.5, 1, 2, 5},
                },
                []string{"model", "language"},
            ),
            
            TTSRequestsTotal: promauto.NewCounterVec(
                prometheus.CounterOpts{
                    Name: "voicehelper_tts_requests_total",
                    Help: "Total number of TTS requests",
                },
                []string{"voice", "language", "status"},
            ),
            
            TTSLatency: promauto.NewHistogramVec(
                prometheus.HistogramOpts{
                    Name: "voicehelper_tts_latency_seconds",
                    Help: "TTS processing latency in seconds",
                    Buckets: []float64{0.1, 0.2, 0.5, 1, 2, 5},
                },
                []string{"voice", "language"},
            ),
            
            // AIæœåŠ¡æŒ‡æ ‡
            LLMRequestsTotal: promauto.NewCounterVec(
                prometheus.CounterOpts{
                    Name: "voicehelper_llm_requests_total",
                    Help: "Total number of LLM requests",
                },
                []string{"model", "provider", "status"},
            ),
            
            LLMTokensUsed: promauto.NewCounterVec(
                prometheus.CounterOpts{
                    Name: "voicehelper_llm_tokens_used_total",
                    Help: "Total number of LLM tokens used",
                },
                []string{"model", "provider", "type"},
            ),
            
            LLMLatency: promauto.NewHistogramVec(
                prometheus.HistogramOpts{
                    Name: "voicehelper_llm_latency_seconds",
                    Help: "LLM processing latency in seconds",
                    Buckets: []float64{0.5, 1, 2, 5, 10, 20, 30},
                },
                []string{"model", "provider"},
            ),
            
            RAGQueryTotal: promauto.NewCounterVec(
                prometheus.CounterOpts{
                    Name: "voicehelper_rag_queries_total",
                    Help: "Total number of RAG queries",
                },
                []string{"index", "status"},
            ),
            
            RAGLatency: promauto.NewHistogramVec(
                prometheus.HistogramOpts{
                    Name: "voicehelper_rag_latency_seconds",
                    Help: "RAG query latency in seconds",
                    Buckets: []float64{0.01, 0.05, 0.1, 0.25, 0.5, 1, 2},
                },
                []string{"index", "type"},
            ),
            
            // ç³»ç»Ÿèµ„æºæŒ‡æ ‡
            MemoryUsage: promauto.NewGauge(
                prometheus.GaugeOpts{
                    Name: "voicehelper_memory_usage_bytes",
                    Help: "Memory usage in bytes",
                },
            ),
            
            CPUUsage: promauto.NewGauge(
                prometheus.GaugeOpts{
                    Name: "voicehelper_cpu_usage_percent",
                    Help: "CPU usage percentage",
                },
            ),
            
            DiskUsage: promauto.NewGauge(
                prometheus.GaugeOpts{
                    Name: "voicehelper_disk_usage_bytes",
                    Help: "Disk usage in bytes",
                },
            ),
            
            // ä¸šåŠ¡æŒ‡æ ‡
            ActiveUsers: promauto.NewGauge(
                prometheus.GaugeOpts{
                    Name: "voicehelper_active_users",
                    Help: "Number of active users",
                },
            ),
            
            TotalConversations: promauto.NewCounterVec(
                prometheus.CounterOpts{
                    Name: "voicehelper_conversations_total",
                    Help: "Total number of conversations",
                },
                []string{"type", "tenant_id"},
            ),
            
            UserSatisfaction: promauto.NewHistogramVec(
                prometheus.HistogramOpts{
                    Name: "voicehelper_user_satisfaction_score",
                    Help: "User satisfaction score",
                    Buckets: []float64{1, 2, 3, 4, 5},
                },
                []string{"tenant_id"},
            ),
        }
    })
    
    return metricsRegistry
}

// ä¾¿æ·æ–¹æ³•
func RecordHTTPRequest(method, endpoint, statusCode, tenantID string, duration time.Duration, requestSize, responseSize float64) {
    registry := GetMetricsRegistry()
    
    registry.HTTPRequestsTotal.WithLabelValues(method, endpoint, statusCode, tenantID).Inc()
    registry.HTTPRequestDuration.WithLabelValues(method, endpoint, tenantID).Observe(duration.Seconds())
    registry.HTTPRequestSize.WithLabelValues(method, endpoint).Observe(requestSize)
    registry.HTTPResponseSize.WithLabelValues(method, endpoint).Observe(responseSize)
}

func RecordVoiceProcessing(processType, model, language string, duration time.Duration) {
    registry := GetMetricsRegistry()
    registry.VoiceProcessingDuration.WithLabelValues(processType, model, language).Observe(duration.Seconds())
}

func RecordASRRequest(model, language, status string, latency time.Duration) {
    registry := GetMetricsRegistry()
    registry.ASRRequestsTotal.WithLabelValues(model, language, status).Inc()
    registry.ASRLatency.WithLabelValues(model, language).Observe(latency.Seconds())
}

func RecordTTSRequest(voice, language, status string, latency time.Duration) {
    registry := GetMetricsRegistry()
    registry.TTSRequestsTotal.WithLabelValues(voice, language, status).Inc()
    registry.TTSLatency.WithLabelValues(voice, language).Observe(latency.Seconds())
}

func RecordLLMRequest(model, provider, status string, latency time.Duration, inputTokens, outputTokens int) {
    registry := GetMetricsRegistry()
    registry.LLMRequestsTotal.WithLabelValues(model, provider, status).Inc()
    registry.LLMLatency.WithLabelValues(model, provider).Observe(latency.Seconds())
    registry.LLMTokensUsed.WithLabelValues(model, provider, "input").Add(float64(inputTokens))
    registry.LLMTokensUsed.WithLabelValues(model, provider, "output").Add(float64(outputTokens))
}

func IncrementWSConnections(connectionType, tenantID string) {
    registry := GetMetricsRegistry()
    registry.WSConnectionsActive.Inc()
    registry.WSConnectionsTotal.WithLabelValues(connectionType, tenantID).Inc()
}

func DecrementWSConnections() {
    registry := GetMetricsRegistry()
    registry.WSConnectionsActive.Dec()
}

func UpdateActiveUsers(count float64) {
    registry := GetMetricsRegistry()
    registry.ActiveUsers.Set(count)
}
```

#### 3.2 ä¸­é—´ä»¶é›†æˆ

```go
// backend/pkg/middleware/metrics_middleware.go
package middleware

import (
    "strconv"
    "time"
    
    "github.com/gin-gonic/gin"
    "your-project/pkg/metrics"
)

func MetricsMiddleware() gin.HandlerFunc {
    return func(c *gin.Context) {
        start := time.Now()
        
        // å¤„ç†è¯·æ±‚
        c.Next()
        
        // è®°å½•æŒ‡æ ‡
        duration := time.Since(start)
        statusCode := strconv.Itoa(c.Writer.Status())
        tenantID := c.GetString("tenant_id")
        if tenantID == "" {
            tenantID = "default"
        }
        
        requestSize := float64(c.Request.ContentLength)
        responseSize := float64(c.Writer.Size())
        
        metrics.RecordHTTPRequest(
            c.Request.Method,
            c.FullPath(),
            statusCode,
            tenantID,
            duration,
            requestSize,
            responseSize,
        )
    }
}
```

### 4. åŸºäºFAISSçš„é«˜æ€§èƒ½RAGç³»ç»Ÿ

#### 4.1 å¢å¼ºç‰ˆRAGæ£€ç´¢æœåŠ¡

```python
# algo/core/enhanced_faiss_rag.py
import asyncio
import faiss
import numpy as np
import pickle
import json
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from sentence_transformers import SentenceTransformer
import logging
from concurrent.futures import ThreadPoolExecutor
import time

logger = logging.getLogger(__name__)

@dataclass
class Document:
    """æ–‡æ¡£æ•°æ®ç»“æ„"""
    id: str
    content: str
    metadata: Dict[str, Any]
    embedding: Optional[np.ndarray] = None
    
@dataclass
class RetrievalResult:
    """æ£€ç´¢ç»“æœ"""
    document: Document
    score: float
    rank: int

class EnhancedFAISSRAG:
    """å¢å¼ºç‰ˆFAISS RAGç³»ç»Ÿ"""
    
    def __init__(
        self,
        embedding_model: str = "BAAI/bge-large-zh-v1.5",
        index_type: str = "HNSW",
        dimension: int = 1024,
        data_dir: str = "data/rag"
    ):
        self.embedding_model_name = embedding_model
        self.embedding_model = None
        self.index_type = index_type
        self.dimension = dimension
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # FAISSç´¢å¼•
        self.index = None
        self.documents: List[Document] = []
        self.id_to_index: Dict[str, int] = {}
        
        # çº¿ç¨‹æ± ç”¨äºå¹¶è¡Œå¤„ç†
        self.executor = ThreadPoolExecutor(max_workers=4)
        
        # ç¼“å­˜
        self.embedding_cache: Dict[str, np.ndarray] = {}
        self.query_cache: Dict[str, List[RetrievalResult]] = {}
        
    async def initialize(self):
        """åˆå§‹åŒ–RAGç³»ç»Ÿ"""
        try:
            # åŠ è½½åµŒå…¥æ¨¡å‹
            logger.info(f"åŠ è½½åµŒå…¥æ¨¡å‹: {self.embedding_model_name}")
            self.embedding_model = SentenceTransformer(self.embedding_model_name)
            self.dimension = self.embedding_model.get_sentence_embedding_dimension()
            
            # å°è¯•åŠ è½½å·²æœ‰ç´¢å¼•
            await self.load_index()
            
            logger.info("FAISS RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _create_faiss_index(self) -> faiss.Index:
        """åˆ›å»ºFAISSç´¢å¼•"""
        if self.index_type == "HNSW":
            # HNSWç´¢å¼•ï¼Œé€‚åˆé«˜ç»´å‘é‡å’Œå¤§è§„æ¨¡æ•°æ®
            index = faiss.IndexHNSWFlat(self.dimension, 32)
            index.hnsw.efConstruction = 200
            index.hnsw.efSearch = 64
        elif self.index_type == "IVF":
            # IVFç´¢å¼•ï¼Œé€‚åˆè¶…å¤§è§„æ¨¡æ•°æ®
            quantizer = faiss.IndexFlatL2(self.dimension)
            index = faiss.IndexIVFFlat(quantizer, self.dimension, 100)
        else:
            # é»˜è®¤ä½¿ç”¨Flatç´¢å¼•
            index = faiss.IndexFlatL2(self.dimension)
            
        return index
    
    async def add_documents(self, documents: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æ·»åŠ æ–‡æ¡£åˆ°ç´¢å¼•"""
        try:
            start_time = time.time()
            
            # å‡†å¤‡æ–‡æ¡£å¯¹è±¡
            doc_objects = []
            texts_to_embed = []
            
            for doc_data in documents:
                doc = Document(
                    id=doc_data.get("id", f"doc_{len(self.documents)}"),
                    content=doc_data.get("content", ""),
                    metadata=doc_data.get("metadata", {})
                )
                doc_objects.append(doc)
                texts_to_embed.append(doc.content)
            
            # æ‰¹é‡ç”ŸæˆåµŒå…¥
            logger.info(f"ä¸º{len(texts_to_embed)}ä¸ªæ–‡æ¡£ç”ŸæˆåµŒå…¥")
            embeddings = await self._generate_embeddings_batch(texts_to_embed)
            
            # åˆ›å»ºæˆ–æ›´æ–°ç´¢å¼•
            if self.index is None:
                self.index = self._create_faiss_index()
            
            # æ·»åŠ å‘é‡åˆ°ç´¢å¼•
            embeddings_array = np.array(embeddings).astype('float32')
            start_index = len(self.documents)
            
            if hasattr(self.index, 'train') and not self.index.is_trained:
                self.index.train(embeddings_array)
            
            self.index.add(embeddings_array)
            
            # æ›´æ–°æ–‡æ¡£å­˜å‚¨
            for i, (doc, embedding) in enumerate(zip(doc_objects, embeddings)):
                doc.embedding = embedding
                self.documents.append(doc)
                self.id_to_index[doc.id] = start_index + i
            
            # ä¿å­˜ç´¢å¼•
            await self.save_index()
            
            processing_time = time.time() - start_time
            
            return {
                "status": "success",
                "documents_added": len(documents),
                "total_documents": len(self.documents),
                "processing_time": processing_time,
                "index_size": self.index.ntotal if self.index else 0
            }
            
        except Exception as e:
            logger.error(f"æ·»åŠ æ–‡æ¡£å¤±è´¥: {e}")
            return {
                "status": "error",
                "error": str(e),
                "documents_added": 0
            }
    
    async def search(
        self,
        query: str,
        top_k: int = 5,
        score_threshold: float = 0.0,
        filters: Optional[Dict[str, Any]] = None
    ) -> List[RetrievalResult]:
        """æœç´¢ç›¸å…³æ–‡æ¡£"""
        try:
            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"{query}:{top_k}:{score_threshold}"
            if cache_key in self.query_cache:
                logger.debug("ä½¿ç”¨ç¼“å­˜ç»“æœ")
                return self.query_cache[cache_key]
            
            if self.index is None or len(self.documents) == 0:
                logger.warning("ç´¢å¼•ä¸ºç©ºæˆ–æœªåˆå§‹åŒ–")
                return []
            
            # ç”ŸæˆæŸ¥è¯¢åµŒå…¥
            query_embedding = await self._generate_embedding(query)
            query_vector = np.array([query_embedding]).astype('float32')
            
            # æ‰§è¡Œæœç´¢
            search_k = min(top_k * 2, len(self.documents))  # æœç´¢æ›´å¤šç»“æœç”¨äºè¿‡æ»¤
            scores, indices = self.index.search(query_vector, search_k)
            
            # æ„å»ºç»“æœ
            results = []
            for rank, (score, idx) in enumerate(zip(scores[0], indices[0])):
                if idx == -1:  # FAISSè¿”å›-1è¡¨ç¤ºæ— æ•ˆç»“æœ
                    continue
                    
                if score < score_threshold:
                    continue
                
                if idx >= len(self.documents):
                    logger.warning(f"ç´¢å¼•è¶…å‡ºèŒƒå›´: {idx}")
                    continue
                
                document = self.documents[idx]
                
                # åº”ç”¨è¿‡æ»¤å™¨
                if filters and not self._apply_filters(document, filters):
                    continue
                
                results.append(RetrievalResult(
                    document=document,
                    score=float(score),
                    rank=rank
                ))
                
                if len(results) >= top_k:
                    break
            
            # ç¼“å­˜ç»“æœ
            self.query_cache[cache_key] = results
            
            return results
            
        except Exception as e:
            logger.error(f"æœç´¢å¤±è´¥: {e}")
            return []
    
    async def hybrid_search(
        self,
        query: str,
        top_k: int = 5,
        semantic_weight: float = 0.7,
        keyword_weight: float = 0.3
    ) -> List[RetrievalResult]:
        """æ··åˆæœç´¢ï¼šè¯­ä¹‰æœç´¢ + å…³é”®è¯æœç´¢"""
        try:
            # è¯­ä¹‰æœç´¢
            semantic_results = await self.search(query, top_k * 2)
            
            # å…³é”®è¯æœç´¢ï¼ˆç®€å•å®ç°ï¼‰
            keyword_results = await self._keyword_search(query, top_k * 2)
            
            # ç»“æœèåˆ
            combined_results = self._combine_search_results(
                semantic_results, 
                keyword_results, 
                semantic_weight, 
                keyword_weight
            )
            
            return combined_results[:top_k]
            
        except Exception as e:
            logger.error(f"æ··åˆæœç´¢å¤±è´¥: {e}")
            return await self.search(query, top_k)  # é™çº§åˆ°è¯­ä¹‰æœç´¢
    
    async def _generate_embedding(self, text: str) -> np.ndarray:
        """ç”Ÿæˆå•ä¸ªæ–‡æœ¬çš„åµŒå…¥"""
        if text in self.embedding_cache:
            return self.embedding_cache[text]
        
        loop = asyncio.get_event_loop()
        embedding = await loop.run_in_executor(
            self.executor,
            self.embedding_model.encode,
            text
        )
        
        self.embedding_cache[text] = embedding
        return embedding
    
    async def _generate_embeddings_batch(self, texts: List[str]) -> List[np.ndarray]:
        """æ‰¹é‡ç”ŸæˆåµŒå…¥"""
        loop = asyncio.get_event_loop()
        embeddings = await loop.run_in_executor(
            self.executor,
            self.embedding_model.encode,
            texts
        )
        return embeddings.tolist()
    
    async def _keyword_search(self, query: str, top_k: int) -> List[RetrievalResult]:
        """å…³é”®è¯æœç´¢ï¼ˆç®€å•TF-IDFå®ç°ï¼‰"""
        # è¿™é‡Œå¯ä»¥é›†æˆæ›´å¤æ‚çš„å…³é”®è¯æœç´¢ç®—æ³•ï¼Œå¦‚BM25
        query_terms = query.lower().split()
        results = []
        
        for idx, doc in enumerate(self.documents):
            content_lower = doc.content.lower()
            score = sum(content_lower.count(term) for term in query_terms)
            
            if score > 0:
                results.append(RetrievalResult(
                    document=doc,
                    score=float(score),
                    rank=idx
                ))
        
        # æŒ‰åˆ†æ•°æ’åº
        results.sort(key=lambda x: x.score, reverse=True)
        return results[:top_k]
    
    def _combine_search_results(
        self,
        semantic_results: List[RetrievalResult],
        keyword_results: List[RetrievalResult],
        semantic_weight: float,
        keyword_weight: float
    ) -> List[RetrievalResult]:
        """åˆå¹¶æœç´¢ç»“æœ"""
        # åˆ›å»ºæ–‡æ¡£IDåˆ°ç»“æœçš„æ˜ å°„
        semantic_map = {result.document.id: result for result in semantic_results}
        keyword_map = {result.document.id: result for result in keyword_results}
        
        # è·å–æ‰€æœ‰æ–‡æ¡£ID
        all_doc_ids = set(semantic_map.keys()) | set(keyword_map.keys())
        
        combined_results = []
        for doc_id in all_doc_ids:
            semantic_score = semantic_map.get(doc_id, RetrievalResult(None, 0.0, 999)).score
            keyword_score = keyword_map.get(doc_id, RetrievalResult(None, 0.0, 999)).score
            
            # å½’ä¸€åŒ–åˆ†æ•°
            semantic_score = semantic_score / max(1.0, max(r.score for r in semantic_results))
            keyword_score = keyword_score / max(1.0, max(r.score for r in keyword_results))
            
            # è®¡ç®—ç»„åˆåˆ†æ•°
            combined_score = semantic_weight * semantic_score + keyword_weight * keyword_score
            
            # è·å–æ–‡æ¡£å¯¹è±¡
            document = semantic_map.get(doc_id, keyword_map.get(doc_id)).document
            
            combined_results.append(RetrievalResult(
                document=document,
                score=combined_score,
                rank=0  # é‡æ–°æ’åºåè®¾ç½®
            ))
        
        # æŒ‰ç»„åˆåˆ†æ•°æ’åº
        combined_results.sort(key=lambda x: x.score, reverse=True)
        
        # æ›´æ–°æ’å
        for rank, result in enumerate(combined_results):
            result.rank = rank
        
        return combined_results
    
    def _apply_filters(self, document: Document, filters: Dict[str, Any]) -> bool:
        """åº”ç”¨è¿‡æ»¤å™¨"""
        for key, value in filters.items():
            if key not in document.metadata:
                return False
            if document.metadata[key] != value:
                return False
        return True
    
    async def save_index(self):
        """ä¿å­˜ç´¢å¼•å’Œæ–‡æ¡£"""
        try:
            if self.index is not None:
                # ä¿å­˜FAISSç´¢å¼•
                index_path = self.data_dir / "faiss.index"
                faiss.write_index(self.index, str(index_path))
                
                # ä¿å­˜æ–‡æ¡£æ•°æ®
                docs_path = self.data_dir / "documents.pkl"
                with open(docs_path, 'wb') as f:
                    pickle.dump({
                        'documents': self.documents,
                        'id_to_index': self.id_to_index
                    }, f)
                
                # ä¿å­˜å…ƒæ•°æ®
                metadata_path = self.data_dir / "metadata.json"
                with open(metadata_path, 'w', encoding='utf-8') as f:
                    json.dump({
                        'embedding_model': self.embedding_model_name,
                        'index_type': self.index_type,
                        'dimension': self.dimension,
                        'total_documents': len(self.documents),
                        'created_at': time.time()
                    }, f, ensure_ascii=False, indent=2)
                
                logger.info(f"ç´¢å¼•å·²ä¿å­˜åˆ° {self.data_dir}")
                
        except Exception as e:
            logger.error(f"ä¿å­˜ç´¢å¼•å¤±è´¥: {e}")
    
    async def load_index(self):
        """åŠ è½½ç´¢å¼•å’Œæ–‡æ¡£"""
        try:
            index_path = self.data_dir / "faiss.index"
            docs_path = self.data_dir / "documents.pkl"
            metadata_path = self.data_dir / "metadata.json"
            
            if not all(p.exists() for p in [index_path, docs_path, metadata_path]):
                logger.info("æœªæ‰¾åˆ°å·²æœ‰ç´¢å¼•ï¼Œå°†åˆ›å»ºæ–°ç´¢å¼•")
                return
            
            # åŠ è½½FAISSç´¢å¼•
            self.index = faiss.read_index(str(index_path))
            
            # åŠ è½½æ–‡æ¡£æ•°æ®
            with open(docs_path, 'rb') as f:
                data = pickle.load(f)
                self.documents = data['documents']
                self.id_to_index = data['id_to_index']
            
            # åŠ è½½å…ƒæ•°æ®
            with open(metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
                logger.info(f"åŠ è½½ç´¢å¼•: {metadata['total_documents']} ä¸ªæ–‡æ¡£")
            
            logger.info(f"ç´¢å¼•å·²ä» {self.data_dir} åŠ è½½")
            
        except Exception as e:
            logger.error(f"åŠ è½½ç´¢å¼•å¤±è´¥: {e}")
            self.index = None
            self.documents = []
            self.id_to_index = {}
    
    async def get_stats(self) -> Dict[str, Any]:
        """è·å–RAGç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_documents": len(self.documents),
            "index_size": self.index.ntotal if self.index else 0,
            "embedding_model": self.embedding_model_name,
            "index_type": self.index_type,
            "dimension": self.dimension,
            "cache_size": len(self.embedding_cache),
            "query_cache_size": len(self.query_cache)
        }

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    # åˆå§‹åŒ–RAGç³»ç»Ÿ
    rag = EnhancedFAISSRAG(
        embedding_model="BAAI/bge-large-zh-v1.5",
        index_type="HNSW"
    )
    
    await rag.initialize()
    
    # æ·»åŠ æ–‡æ¡£
    documents = [
        {
            "id": "doc1",
            "content": "VoiceHelperæ˜¯ä¸€ä¸ªæ™ºèƒ½è¯­éŸ³åŠ©æ‰‹å¹³å°",
            "metadata": {"category": "product", "language": "zh"}
        },
        {
            "id": "doc2", 
            "content": "æ”¯æŒå®æ—¶è¯­éŸ³è¯†åˆ«å’Œè¯­éŸ³åˆæˆåŠŸèƒ½",
            "metadata": {"category": "feature", "language": "zh"}
        }
    ]
    
    result = await rag.add_documents(documents)
    print(f"æ·»åŠ æ–‡æ¡£ç»“æœ: {result}")
    
    # æœç´¢
    search_results = await rag.search("è¯­éŸ³åŠ©æ‰‹åŠŸèƒ½", top_k=3)
    for result in search_results:
        print(f"æ–‡æ¡£: {result.document.content}")
        print(f"åˆ†æ•°: {result.score}")
        print(f"æ’å: {result.rank}")
        print("---")

if __name__ == "__main__":
    asyncio.run(main())
```

---

## ğŸ“ˆ å®æ–½ä¼˜å…ˆçº§å’Œæ—¶é—´è§„åˆ’

### Phase 1: åŸºç¡€è®¾æ–½ä¿®å¤ (2-3å‘¨)
1. **Prometheusç›‘æ§ç³»ç»Ÿé‡å»º** (1å‘¨)
2. **WebSocketè¯­éŸ³å¤„ç†å™¨é‡å»º** (1-2å‘¨)
3. **åŸºç¡€æœåŠ¡å¥åº·æ£€æŸ¥** (å‡ å¤©)

### Phase 2: æ ¸å¿ƒåŠŸèƒ½å®ç° (4-6å‘¨)
1. **OpenAI Whisper ASRé›†æˆ** (2å‘¨)
2. **Edge-TTSè¯­éŸ³åˆæˆé›†æˆ** (1å‘¨)
3. **Rasaå¯¹è¯ç®¡ç†ç³»ç»Ÿ** (2-3å‘¨)
4. **å¢å¼ºç‰ˆFAISS RAGç³»ç»Ÿ** (2å‘¨)

### Phase 3: é«˜çº§åŠŸèƒ½å®Œå–„ (6-8å‘¨)
1. **å¤šæ¨¡æ€å¤„ç†èƒ½åŠ›** (3-4å‘¨)
2. **å¤šå¹³å°å®¢æˆ·ç«¯å®Œå–„** (2-3å‘¨)
3. **ä¼ä¸šçº§å®‰å…¨åŠŸèƒ½** (2-3å‘¨)

---

## ğŸ¯ é¢„æœŸæ•ˆæœ

å®Œæˆæ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½åï¼ŒVoiceHelperå°†çœŸæ­£å…·å¤‡ï¼š

âœ… **å®æ—¶è¯­éŸ³å¤„ç†**: åŸºäºWhisperçš„<300mså»¶è¿ŸASR  
âœ… **æ™ºèƒ½å¯¹è¯ç®¡ç†**: åŸºäºRasaçš„å¤šè½®å¯¹è¯èƒ½åŠ›  
âœ… **é«˜æ€§èƒ½æ£€ç´¢**: åŸºäºFAISSçš„æ¯«ç§’çº§å‘é‡æœç´¢  
âœ… **å®Œæ•´ç›‘æ§ä½“ç³»**: åŸºäºPrometheusçš„å…¨é“¾è·¯è§‚æµ‹  
âœ… **ä¼ä¸šçº§æ¶æ„**: æ”¯æŒå¤šç§Ÿæˆ·å’Œé«˜å¹¶å‘åœºæ™¯  

è¿™å°†ä½¿é¡¹ç›®ä»å½“å‰çš„"æ¼”ç¤ºç‰ˆæœ¬"çœŸæ­£æå‡åˆ°"ç”Ÿäº§å°±ç»ª"çš„ä¼ä¸šçº§AIåŠ©æ‰‹å¹³å°æ°´å¹³ã€‚

---

*æ–‡æ¡£æ›´æ–°æ—¶é—´: 2025å¹´9æœˆ23æ—¥*  
*åŸºäºæœ€æ–°å¼€æºæŠ€æœ¯æ ˆ: OpenAI Whisper + Rasa + FAISS + Prometheus*
