# ğŸ› ï¸ å¼€å‘æŒ‡å— - VoiceHelper AI

## ğŸ“‹ æ¦‚è¿°

æœ¬æŒ‡å—æä¾›äº†VoiceHelper AIæ™ºèƒ½å¯¹è¯ç³»ç»Ÿçš„å®Œæ•´å¼€å‘æŒ‡å—ï¼ŒåŒ…æ‹¬SDKä½¿ç”¨ã€æµ‹è¯•æ•°æ®é›†ã€å°ç¨‹åºå¼€å‘ç­‰å†…å®¹ã€‚

---

## ğŸš€ SDK ä½¿ç”¨æŒ‡å—

### å¿«é€Ÿå¼€å§‹

#### JavaScript/TypeScript SDK

```bash
npm install @voicehelper/sdk
```

```typescript
import { VoiceHelperSDK } from '@voicehelper/sdk';

const client = new VoiceHelperSDK({
  apiKey: 'your-api-key',
  baseURL: 'https://api.voicehelper.ai/v1'
});

// æ™ºèƒ½å¯¹è¯
const response = await client.createChatCompletion({
  messages: [{ role: 'user', content: 'ä½ å¥½ï¼' }],
  model: 'gpt-4'
});

// è¯­éŸ³è½¬æ–‡å­—
const transcription = await client.transcribeAudio({
  file: audioFile,
  model: 'whisper-1'
});
```

#### Python SDK

```bash
pip install voicehelper-sdk
```

```python
from voicehelper_sdk import VoiceHelperSDK, VoiceHelperConfig

config = VoiceHelperConfig(api_key="your-api-key")
client = VoiceHelperSDK(config)

# æ™ºèƒ½å¯¹è¯
response = await client.create_chat_completion({
    "messages": [{"role": "user", "content": "ä½ å¥½ï¼"}],
    "model": "gpt-4"
})

# è¯­éŸ³è½¬æ–‡å­—
with open("audio.wav", "rb") as audio_file:
    transcription = await client.transcribe_audio(audio_file)
```

### é«˜çº§åŠŸèƒ½

#### 1. æµå¼å¯¹è¯

```typescript
// JavaScriptæµå¼å“åº”
await client.messages.sendStream(
  conversationId,
  { content: 'è¯·è§£é‡Šäººå·¥æ™ºèƒ½', stream: true },
  (event) => {
    switch (event.type) {
      case 'delta':
        process.stdout.write(event.content || '');
        break;
      case 'done':
        console.log(`\næ¶ˆæ¯å®Œæˆï¼ŒID: ${event.message_id}`);
        break;
      case 'error':
        console.error('æµå¼é”™è¯¯:', event.error);
        break;
    }
  }
);
```

```python
# Pythonæµå¼å“åº”
async for event in client.messages.send_stream(
    conversation_id,
    SendMessageRequest(content="è¯·è§£é‡Šäººå·¥æ™ºèƒ½")
):
    if event.type == "delta":
        print(event.content, end="", flush=True)
    elif event.type == "done":
        print(f"\næ¶ˆæ¯ID: {event.message_id}")
```

#### 2. å¤šæ¨¡æ€å¤„ç†

```typescript
// è¯­éŸ³æ¶ˆæ¯å¤„ç†
class MultiModalChat {
  async sendVoiceMessage(audioBlob: Blob): Promise<void> {
    // è¯­éŸ³è½¬æ–‡å­—
    const transcription = await this.client.voice.transcribe({
      audio: audioBlob,
      language: 'zh-CN'
    });

    // å‘é€æ–‡å­—æ¶ˆæ¯è·å–å›å¤
    let responseText = '';
    await this.client.messages.sendStream(
      this.conversationId,
      { content: transcription.text, modality: 'voice' },
      (event) => {
        if (event.type === 'delta') {
          responseText += event.content || '';
        } else if (event.type === 'done') {
          this.synthesizeAndPlayResponse(responseText);
        }
      }
    );
  }

  private async synthesizeAndPlayResponse(text: string): Promise<void> {
    const audioBuffer = await this.client.voice.synthesize({
      text: text,
      voice: 'female',
      speed: 1.0
    });

    const audioBlob = new Blob([audioBuffer], { type: 'audio/wav' });
    const audioUrl = URL.createObjectURL(audioBlob);
    const audio = new Audio(audioUrl);
    audio.play();
  }
}
```

#### 3. é”™è¯¯å¤„ç†å’Œé‡è¯•

```typescript
import { APIError, NetworkError, ValidationError } from '@voicehelper/sdk';

class RobustClient {
  async sendMessageWithRetry(conversationId: string, content: string): Promise<string> {
    const maxRetries = 3;
    const baseDelay = 1000;

    for (let attempt = 0; attempt < maxRetries; attempt++) {
      try {
        let response = '';
        await this.client.messages.sendStream(
          conversationId,
          { content },
          (event) => {
            if (event.type === 'delta') {
              response += event.content || '';
            }
          }
        );
        return response;
      } catch (error) {
        if (error instanceof APIError && error.isRateLimitError) {
          const delay = baseDelay * Math.pow(2, attempt);
          console.log(`è§¦å‘é™æµï¼Œç­‰å¾… ${delay}ms åé‡è¯•...`);
          await new Promise(resolve => setTimeout(resolve, delay));
          continue;
        }
        
        if (attempt === maxRetries - 1) {
          throw error;
        }
        
        console.log(`è¯·æ±‚å¤±è´¥ï¼Œé‡è¯•ä¸­... (${attempt + 1}/${maxRetries})`);
        await new Promise(resolve => setTimeout(resolve, baseDelay));
      }
    }
    
    throw new Error('è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°');
  }
}
```

---

## ğŸ§ª æµ‹è¯•æ•°æ®é›†

### æ•°æ®é›†ç»“æ„

```
tests/datasets/
â”œâ”€â”€ chat/                    # èŠå¤©å¯¹è¯æµ‹è¯•æ•°æ®é›†
â”‚   â”œâ”€â”€ conversation_scenarios.json      # å¤šè½®å¯¹è¯åœºæ™¯
â”‚   â”œâ”€â”€ intent_classification.json       # æ„å›¾è¯†åˆ«æµ‹è¯•
â”‚   â””â”€â”€ emotion_analysis.json           # æƒ…æ„Ÿåˆ†ææµ‹è¯•
â”œâ”€â”€ voice/                   # è¯­éŸ³äº¤äº’æµ‹è¯•æ•°æ®é›†
â”‚   â”œâ”€â”€ asr_test_cases.json             # è¯­éŸ³è¯†åˆ«æµ‹è¯•
â”‚   â”œâ”€â”€ tts_test_cases.json             # è¯­éŸ³åˆæˆæµ‹è¯•
â”‚   â””â”€â”€ voice_emotion_test.json         # è¯­éŸ³æƒ…æ„Ÿæµ‹è¯•
â”œâ”€â”€ rag/                     # RAGæ£€ç´¢æµ‹è¯•æ•°æ®é›†
â”‚   â”œâ”€â”€ knowledge_base_samples.json     # çŸ¥è¯†åº“æ ·æœ¬
â”‚   â””â”€â”€ vector_search_test.json         # å‘é‡æ£€ç´¢æµ‹è¯•
â”œâ”€â”€ agent/                   # æ™ºèƒ½ä»£ç†æµ‹è¯•æ•°æ®é›†
â”‚   â”œâ”€â”€ tool_calling_test.json          # å·¥å…·è°ƒç”¨æµ‹è¯•
â”‚   â””â”€â”€ reasoning_chain_test.json       # æ¨ç†é“¾æµ‹è¯•
â”œâ”€â”€ performance/             # æ€§èƒ½æµ‹è¯•æ•°æ®é›†
â”œâ”€â”€ security/                # å®‰å…¨æµ‹è¯•æ•°æ®é›†
â””â”€â”€ integration/             # é›†æˆæµ‹è¯•æ•°æ®é›†
```

### æµ‹è¯•æ•°æ®é›†åˆ†ç±»

#### 1. èŠå¤©å¯¹è¯æµ‹è¯• (Chat)

**ç›®æ ‡**: éªŒè¯èŠå¤©æœºå™¨äººçš„å¯¹è¯èƒ½åŠ›ã€æ„å›¾è¯†åˆ«å’Œæƒ…æ„Ÿåˆ†æ

- **conversation_scenarios.json**: 50ä¸ªå¤šè½®å¯¹è¯åœºæ™¯
  - äº§å“å’¨è¯¢ã€å®¢æˆ·æŠ•è¯‰ã€æŠ€æœ¯æ”¯æŒç­‰
  - ä¸Šä¸‹æ–‡ç†è§£ã€æƒ…æ„Ÿè¯†åˆ«ã€å¼‚å¸¸å¤„ç†
  
- **intent_classification.json**: 200ä¸ªæ„å›¾åˆ†ç±»æ ·æœ¬
  - 15ç§æ„å›¾ç±»å‹ï¼šé—®å€™ã€å’¨è¯¢ã€æŠ•è¯‰ã€é¢„è®¢ç­‰
  - åŒ…å«æŒ‘æˆ˜æ€§æ¡ˆä¾‹å’Œæ¨¡ç³Šè¡¨è¾¾
  
- **emotion_analysis.json**: 150ä¸ªæƒ…æ„Ÿåˆ†ææ ·æœ¬
  - 8ç§æƒ…æ„Ÿç±»å‹ï¼šå¼€å¿ƒã€æ„¤æ€’ã€æ‚²ä¼¤ã€ç„¦è™‘ç­‰
  - å¤åˆæƒ…æ„Ÿå’Œæ–‡åŒ–è¯­å¢ƒæµ‹è¯•

#### 2. è¯­éŸ³äº¤äº’æµ‹è¯• (Voice)

**ç›®æ ‡**: éªŒè¯è¯­éŸ³è¯†åˆ«ã€è¯­éŸ³åˆæˆå’Œè¯­éŸ³æƒ…æ„Ÿçš„å‡†ç¡®æ€§

- **asr_test_cases.json**: 100ä¸ªè¯­éŸ³è¯†åˆ«æµ‹è¯•
  - æ¸…æ™°è¯­éŸ³ã€å™ªéŸ³ç¯å¢ƒã€å£éŸ³è¯­éŸ³ç­‰
  - æŠ€æœ¯æœ¯è¯­ã€å¿«é€Ÿè¯­éŸ³ã€æƒ…æ„Ÿè¯­éŸ³
  
- **tts_test_cases.json**: 80ä¸ªè¯­éŸ³åˆæˆæµ‹è¯•
  - åŸºç¡€å¥å­ã€æƒ…æ„Ÿè¯­éŸ³ã€æŠ€æœ¯å†…å®¹
  - é•¿æ–‡æœ¬ã€ç‰¹æ®Šå­—ç¬¦å¤„ç†
  
- **voice_emotion_test.json**: 120ä¸ªè¯­éŸ³æƒ…æ„Ÿæµ‹è¯•
  - æƒ…æ„Ÿè¯†åˆ«å’Œæƒ…æ„Ÿåˆæˆ
  - è·¨æ–‡åŒ–è¯­å¢ƒå’Œå¤åˆæƒ…æ„Ÿ

#### 3. RAGæ£€ç´¢æµ‹è¯• (RAG)

**ç›®æ ‡**: éªŒè¯çŸ¥è¯†æ£€ç´¢å’Œæ–‡æ¡£é—®ç­”çš„å‡†ç¡®æ€§

- **knowledge_base_samples.json**: 200ä¸ªæ–‡æ¡£æ ·æœ¬
  - äº§å“æ–‡æ¡£ã€æŠ€æœ¯è§„æ ¼ã€FAQã€æ”¿ç­–ç­‰
  - å¤æ‚æŸ¥è¯¢å’Œè¾¹ç•Œæƒ…å†µæµ‹è¯•
  
- **vector_search_test.json**: 1000ä¸ªå‘é‡æ£€ç´¢æµ‹è¯•
  - è¯­ä¹‰ç›¸ä¼¼åº¦ã€è·¨é¢†åŸŸæŸ¥è¯¢ã€å¤šè¯­è¨€
  - æ€§èƒ½æµ‹è¯•å’Œé²æ£’æ€§éªŒè¯

### ä½¿ç”¨æµ‹è¯•æ•°æ®

```bash
# è¿è¡ŒèŠå¤©å¯¹è¯æµ‹è¯•
python -m pytest tests/chat/ -v

# è¿è¡Œæ€§èƒ½æµ‹è¯•
python -m pytest tests/performance/ -v

# è¿è¡Œå®‰å…¨æµ‹è¯•
python -m pytest tests/security/ -v
```

```python
import json

# åŠ è½½å¯¹è¯æµ‹è¯•æ•°æ®
with open('tests/datasets/chat/conversation_scenarios.json') as f:
    chat_data = json.load(f)

# è·å–æµ‹è¯•åœºæ™¯
scenarios = chat_data['scenarios']
for scenario in scenarios:
    print(f"æµ‹è¯•åœºæ™¯: {scenario['title']}")
```

---

## ğŸ“± å¾®ä¿¡å°ç¨‹åºå¼€å‘

### åŠŸèƒ½ç‰¹æ€§

- ğŸ¤ **è¯­éŸ³äº¤äº’**: æ”¯æŒå®æ—¶è¯­éŸ³è¾“å…¥å’ŒTTSè¯­éŸ³åˆæˆ
- ğŸ’¬ **æ–‡æœ¬èŠå¤©**: ä¼ ç»Ÿçš„æ–‡æœ¬æ¶ˆæ¯äº¤äº’
- ğŸ”„ **æµå¼å“åº”**: æ”¯æŒSSEå’ŒWebSocketåŒåè®®
- ğŸ” **å¾®ä¿¡ç™»å½•**: é›†æˆå¾®ä¿¡æˆæƒç™»å½•
- ğŸ“± **è‡ªé€‚åº”**: æ ¹æ®iOS/Androidè‡ªåŠ¨è°ƒæ•´éŸ³é¢‘é…ç½®
- ğŸ”Œ **æ–­çº¿é‡è¿**: è‡ªåŠ¨å¤„ç†ç½‘ç»œä¸­æ–­å’Œé‡è¿

### æŠ€æœ¯æ¶æ„

#### æ ¸å¿ƒæ–‡ä»¶

- `app.js` - å°ç¨‹åºä¸»å…¥å£ï¼Œå…¨å±€çŠ¶æ€ç®¡ç†
- `pages/chat/chat.js` - èŠå¤©é¡µé¢ï¼Œæ ¸å¿ƒäº¤äº’é€»è¾‘
- `app.json` - å°ç¨‹åºé…ç½®æ–‡ä»¶

#### éŸ³é¢‘å¤„ç†

- **å½•éŸ³**: ä½¿ç”¨ `wx.getRecorderManager()` 
- **æ’­æ”¾**: ä½¿ç”¨ `wx.createInnerAudioContext()` å’Œ `wx.createWebAudioContext()`
- **æ ¼å¼**: Androidä½¿ç”¨MP3ï¼ŒiOSä½¿ç”¨AAC
- **é‡‡æ ·ç‡**: 16kHzï¼Œå•å£°é“

#### ç½‘ç»œé€šä¿¡

- **WebSocket**: ç”¨äºå®æ—¶è¯­éŸ³æµ
- **HTTP SSE**: ç”¨äºæ–‡æœ¬èŠå¤©æµå¼å“åº”
- **æ–­çº¿é‡è¿**: 3ç§’è‡ªåŠ¨é‡è¿æœºåˆ¶

### å¼€å‘é…ç½®

```javascript
// app.js
globalData: {
  apiUrl: 'https://your-api-domain.com/api/v1',
  wsUrl: 'wss://your-api-domain.com/api/v1'
}
```

### APIæ¥å£

#### WebSocketåè®®

**è¿æ¥åœ°å€**: `/api/v1/voice/stream`

**æ¶ˆæ¯ç±»å‹**:
- `start` - åˆå§‹åŒ–è¿æ¥
- `audio` - å‘é€éŸ³é¢‘æ•°æ®
- `stop` - åœæ­¢å½•éŸ³
- `cancel` - å–æ¶ˆè¯·æ±‚

#### HTTPæ¥å£

- `POST /api/v1/chat/stream` - æ–‡æœ¬èŠå¤©
- `POST /api/v1/auth/wechat/miniprogram/login` - å¾®ä¿¡ç™»å½•
- `GET /api/v1/conversations/{id}/messages` - è·å–å†å²æ¶ˆæ¯

### éƒ¨ç½²æ³¨æ„äº‹é¡¹

1. **åŸŸåé…ç½®**: åœ¨å¾®ä¿¡å…¬ä¼—å¹³å°é…ç½®åˆæ³•åŸŸå
2. **HTTPS**: æ‰€æœ‰æ¥å£å¿…é¡»ä½¿ç”¨HTTPS
3. **WSS**: WebSocketå¿…é¡»ä½¿ç”¨WSSåè®®
4. **æƒé™ç”³è¯·**: éœ€è¦ç”³è¯·å½•éŸ³æƒé™

### æ€§èƒ½ä¼˜åŒ–

1. **éŸ³é¢‘ç¼“å†²**: ä½¿ç”¨é˜Ÿåˆ—ç®¡ç†éŸ³é¢‘æ’­æ”¾
2. **æ¶ˆæ¯åˆ†é¡µ**: å†å²æ¶ˆæ¯åˆ†é¡µåŠ è½½
3. **é˜²æŠ–å¤„ç†**: è¾“å…¥å’Œå‘é€æ·»åŠ é˜²æŠ–
4. **èµ„æºæ¸…ç†**: é¡µé¢å¸è½½æ—¶æ¸…ç†å®šæ—¶å™¨å’Œè¿æ¥

---

## ğŸ”§ å¼€å‘æœ€ä½³å®è·µ

### 1. è¿æ¥æ± å’Œèµ„æºç®¡ç†

```typescript
class VoiceHelperManager {
  private static instance: VoiceHelperManager;
  private client: VoiceHelperSDK;

  private constructor(apiKey: string) {
    this.client = new VoiceHelperSDK({
      apiKey,
      timeout: 30000,
    });
  }

  static getInstance(apiKey: string): VoiceHelperManager {
    if (!VoiceHelperManager.instance) {
      VoiceHelperManager.instance = new VoiceHelperManager(apiKey);
    }
    return VoiceHelperManager.instance;
  }

  getClient(): VoiceHelperSDK {
    return this.client;
  }
}
```

### 2. ç¼“å­˜å’Œæ€§èƒ½ä¼˜åŒ–

```python
import asyncio
from typing import Dict, Optional
from datetime import datetime, timedelta
from voicehelper_sdk import VoiceHelperSDK, Conversation

class CachedVoiceHelperClient:
    def __init__(self, api_key: str):
        self.client = VoiceHelperSDK(api_key=api_key)
        self.conversation_cache: Dict[str, tuple[Conversation, datetime]] = {}
        self.cache_ttl = timedelta(minutes=30)
    
    async def get_conversation_cached(self, conversation_id: str) -> Optional[Conversation]:
        """è·å–ç¼“å­˜çš„å¯¹è¯ä¿¡æ¯"""
        if conversation_id in self.conversation_cache:
            conversation, cached_at = self.conversation_cache[conversation_id]
            if datetime.now() - cached_at < self.cache_ttl:
                return conversation
            else:
                # ç¼“å­˜è¿‡æœŸï¼Œåˆ é™¤
                del self.conversation_cache[conversation_id]
        
        # ä»APIè·å–å¹¶ç¼“å­˜
        try:
            conversation = await self.client.conversations.get(conversation_id)
            self.conversation_cache[conversation_id] = (conversation, datetime.now())
            return conversation
        except Exception:
            return None
```

### 3. ç›‘æ§å’Œæ—¥å¿—

```typescript
class MonitoredVoiceHelperClient {
  private client: VoiceHelperSDK;
  private metrics = {
    requests: 0,
    errors: 0,
    latency: [] as number[]
  };

  async sendMessage(conversationId: string, content: string): Promise<string> {
    const startTime = Date.now();
    this.metrics.requests++;

    try {
      let response = '';
      await this.client.messages.sendStream(
        conversationId,
        { content },
        (event) => {
          if (event.type === 'delta') {
            response += event.content || '';
          }
        }
      );

      const latency = Date.now() - startTime;
      this.metrics.latency.push(latency);
      
      console.log(`è¯·æ±‚æˆåŠŸ - å»¶è¿Ÿ: ${latency}ms`);
      return response;
    } catch (error) {
      this.metrics.errors++;
      console.error(`è¯·æ±‚å¤±è´¥: ${error.message}`);
      throw error;
    }
  }

  getMetrics() {
    const avgLatency = this.metrics.latency.length > 0
      ? this.metrics.latency.reduce((a, b) => a + b, 0) / this.metrics.latency.length
      : 0;

    return {
      totalRequests: this.metrics.requests,
      totalErrors: this.metrics.errors,
      errorRate: this.metrics.requests > 0 ? this.metrics.errors / this.metrics.requests : 0,
      averageLatency: avgLatency
    };
  }
}
```

---

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡

### åŠŸèƒ½æ€§æŒ‡æ ‡
- **å‡†ç¡®ç‡**: æ­£ç¡®ç»“æœ / æ€»æµ‹è¯•æ•°
- **å¬å›ç‡**: æ‰¾åˆ°çš„ç›¸å…³ç»“æœ / æ€»ç›¸å…³ç»“æœ
- **F1åˆ†æ•°**: ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡

### æ€§èƒ½æŒ‡æ ‡
- **å“åº”æ—¶é—´**: P50, P95, P99å»¶è¿Ÿ
- **ååé‡**: æ¯ç§’å¤„ç†è¯·æ±‚æ•°
- **å¹¶å‘èƒ½åŠ›**: æœ€å¤§å¹¶å‘ç”¨æˆ·æ•°

### è´¨é‡æŒ‡æ ‡
- **å¯ç”¨æ€§**: ç³»ç»Ÿæ­£å¸¸è¿è¡Œæ—¶é—´æ¯”ä¾‹
- **é”™è¯¯ç‡**: é”™è¯¯è¯·æ±‚ / æ€»è¯·æ±‚æ•°
- **ç”¨æˆ·æ»¡æ„åº¦**: åŸºäºå“åº”è´¨é‡çš„è¯„åˆ†

---

## ğŸ¤ è´¡çŒ®æŒ‡å—

### æ·»åŠ æ–°åŠŸèƒ½
1. Forké¡¹ç›®å¹¶åˆ›å»ºç‰¹æ€§åˆ†æ”¯
2. æŒ‰ç…§ç°æœ‰æ ¼å¼æ·»åŠ åŠŸèƒ½ä»£ç 
3. ç¼–å†™ç›¸åº”çš„æµ‹è¯•ç”¨ä¾‹
4. æäº¤Pull Request

### æŠ¥å‘Šé—®é¢˜
1. ä½¿ç”¨GitHub IssuesæŠ¥å‘Šé—®é¢˜
2. æä¾›è¯¦ç»†çš„é—®é¢˜æè¿°å’Œå¤ç°æ­¥éª¤
3. åŒ…å«ç›¸å…³çš„æµ‹è¯•æ•°æ®å’Œæ—¥å¿—

### æ”¹è¿›å»ºè®®
1. æå‡ºå¼€å‘æµç¨‹æ”¹è¿›å»ºè®®
2. åˆ†äº«å¼€å‘å·¥å…·å’Œæ–¹æ³•
3. å‚ä¸ä»£ç å®¡æŸ¥å’Œè®¨è®º

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

- **å¼€å‘è€…æ–‡æ¡£**: [https://docs.voicehelper.ai](https://docs.voicehelper.ai)
- **APIå‚è€ƒ**: [https://api.voicehelper.ai/docs](https://api.voicehelper.ai/docs)
- **GitHub Issues**: [æäº¤é—®é¢˜å’Œå»ºè®®](https://github.com/voicehelper/voicehelper/issues)
- **å¼€å‘è€…ç¤¾åŒº**: [Discord](https://discord.gg/voicehelper)

---

*æœ€åæ›´æ–°: 2025-09-22*  
*ç‰ˆæœ¬: v1.9.0*  
*ç»´æŠ¤è€…: VoiceHelperå¼€å‘å›¢é˜Ÿ*
