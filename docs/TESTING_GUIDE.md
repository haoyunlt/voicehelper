# VoiceHelper æµ‹è¯•æŒ‡å—

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»VoiceHelperé¡¹ç›®çš„æµ‹è¯•ç­–ç•¥ã€æµ‹è¯•ç”¨ä¾‹è®¾è®¡å’Œæµ‹è¯•æ‰§è¡Œæ–¹æ³•ã€‚

## ğŸ“‹ ç›®å½•

- [æµ‹è¯•æ¶æ„æ¦‚è§ˆ](#æµ‹è¯•æ¶æ„æ¦‚è§ˆ)
- [æµ‹è¯•ç¯å¢ƒå‡†å¤‡](#æµ‹è¯•ç¯å¢ƒå‡†å¤‡)
- [æµ‹è¯•ç±»å‹è¯´æ˜](#æµ‹è¯•ç±»å‹è¯´æ˜)
- [æµ‹è¯•æ‰§è¡ŒæŒ‡å—](#æµ‹è¯•æ‰§è¡ŒæŒ‡å—)
- [æ€§èƒ½æµ‹è¯•è¯¦è§£](#æ€§èƒ½æµ‹è¯•è¯¦è§£)
- [æµ‹è¯•æŠ¥å‘Šåˆ†æ](#æµ‹è¯•æŠ¥å‘Šåˆ†æ)
- [æŒç»­é›†æˆé…ç½®](#æŒç»­é›†æˆé…ç½®)
- [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

## ğŸ—ï¸ æµ‹è¯•æ¶æ„æ¦‚è§ˆ

VoiceHelperé‡‡ç”¨å¤šå±‚æ¬¡æµ‹è¯•ç­–ç•¥ï¼Œç¡®ä¿ç³»ç»Ÿçš„å¯é æ€§å’Œæ€§èƒ½ï¼š

```text
æµ‹è¯•é‡‘å­—å¡”
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   E2E Tests     â”‚  â† ç«¯åˆ°ç«¯æµ‹è¯• (å°‘é‡)
    â”‚   (UI/Workflow) â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ Integration     â”‚  â† é›†æˆæµ‹è¯• (é€‚é‡)
    â”‚ Tests (API)     â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚   Unit Tests    â”‚  â† å•å…ƒæµ‹è¯• (å¤§é‡)
    â”‚ (Components)    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Performance     â”‚  â† æ€§èƒ½æµ‹è¯• (ä¸“é¡¹)
         â”‚ Tests           â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```text

### æµ‹è¯•è¦†ç›–èŒƒå›´

| æµ‹è¯•å±‚çº§ | è¦†ç›–èŒƒå›´ | æµ‹è¯•å·¥å…· | æ‰§è¡Œé¢‘ç‡ |
|---------|---------|----------|----------|
| **å•å…ƒæµ‹è¯•** | å‡½æ•°ã€ç±»ã€æ¨¡å— | pytest | æ¯æ¬¡æäº¤ |
| **é›†æˆæµ‹è¯•** | APIæ¥å£ã€æœåŠ¡é—´è°ƒç”¨ | pytest + requests | æ¯æ—¥æ„å»º |
| **ç«¯åˆ°ç«¯æµ‹è¯•** | å®Œæ•´ä¸šåŠ¡æµç¨‹ | pytest + selenium | å‘å¸ƒå‰ |
| **æ€§èƒ½æµ‹è¯•** | è´Ÿè½½ã€å‹åŠ›ã€åŸºå‡† | locust + è‡ªå®šä¹‰è„šæœ¬ | å®šæœŸæ‰§è¡Œ |

## ğŸ› ï¸ æµ‹è¯•ç¯å¢ƒå‡†å¤‡

### 1. å®‰è£…æµ‹è¯•ä¾èµ–

```bash
# å®‰è£…æµ‹è¯•ä¾èµ–
pip install -r requirements-test.txt

# æˆ–è€…ä½¿ç”¨è„šæœ¬è‡ªåŠ¨æ£€æŸ¥å’Œå®‰è£…
./scripts/run_tests.sh --check
```text

### 2. ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»ºæµ‹è¯•ç¯å¢ƒé…ç½®æ–‡ä»¶ `.env.test`ï¼š

```bash
# æœåŠ¡åœ°å€é…ç½®
TEST_BACKEND_URL=http://localhost:8080
TEST_ALGO_URL=http://localhost:8000
TEST_FRONTEND_URL=http://localhost:3000
TEST_WS_URL=ws://localhost:8080

# æµ‹è¯•è¶…æ—¶é…ç½®
TEST_TIMEOUT=30
TEST_API_RESPONSE_TIME=2.0
TEST_WS_CONNECT_TIME=5.0
TEST_SUCCESS_RATE=95.0

# æµ‹è¯•æ•°æ®ç›®å½•
TEST_DATA_DIR=tests/data

# æ•°æ®åº“é…ç½®ï¼ˆæµ‹è¯•ç”¨ï¼‰
TEST_DATABASE_URL=postgresql://test:test@localhost:5432/voicehelper_test
TEST_REDIS_URL=redis://localhost:6379/1

# æ—¥å¿—çº§åˆ«
LOG_LEVEL=INFO
TESTING=true
```text

### 3. å¯åŠ¨æµ‹è¯•æœåŠ¡

```bash
# å¯åŠ¨åç«¯æœåŠ¡
cd backend && go run cmd/server/main.go &

# å¯åŠ¨ç®—æ³•æœåŠ¡
cd algo && python app/main.py &

# å¯åŠ¨å‰ç«¯æœåŠ¡ï¼ˆå¯é€‰ï¼Œç”¨äºE2Eæµ‹è¯•ï¼‰
cd frontend && npm run dev &
```text

## ğŸ“ æµ‹è¯•ç±»å‹è¯´æ˜

### 1. å•å…ƒæµ‹è¯• (Unit Tests)

**ç›®æ ‡**ï¼šæµ‹è¯•å•ä¸ªå‡½æ•°ã€ç±»æˆ–æ¨¡å—çš„åŠŸèƒ½æ­£ç¡®æ€§

**ä½ç½®**ï¼š`tests/unit/`

**ç‰¹ç‚¹**ï¼š
- å¿«é€Ÿæ‰§è¡Œï¼ˆ< 1ç§’ï¼‰
- æ— å¤–éƒ¨ä¾èµ–
- é«˜è¦†ç›–ç‡ï¼ˆç›®æ ‡ > 80%ï¼‰

**ç¤ºä¾‹**ï¼š

```python
# tests/unit/backend/test_handlers.py
def test_health_check_success():
    """æµ‹è¯•å¥åº·æ£€æŸ¥æˆåŠŸ"""
    services = Mock()
    handlers = Handlers(services)
    
    mock_context = Mock()
    handlers.HealthCheck(mock_context)
    
    mock_context.JSON.assert_called_once()
    call_args = mock_context.JSON.call_args
    assert call_args[0][0] == 200
    assert call_args[0][1]["status"] == "ok"
```text

### 2. é›†æˆæµ‹è¯• (Integration Tests)

**ç›®æ ‡**ï¼šæµ‹è¯•æœåŠ¡é—´çš„æ¥å£å’Œæ•°æ®æµ

**ä½ç½®**ï¼š`tests/integration/`

**ç‰¹ç‚¹**ï¼š
- éœ€è¦çœŸå®æœåŠ¡è¿è¡Œ
- æµ‹è¯•APIæ¥å£
- éªŒè¯æ•°æ®ä¸€è‡´æ€§

**ç¤ºä¾‹**ï¼š

```python
# tests/integration/test_api_endpoints.py
def test_chat_completion_api(self, api_base_url, test_auth_token):
    """æµ‹è¯•èŠå¤©å®ŒæˆAPI"""
    headers = {"Authorization": f"Bearer {test_auth_token}"}
    chat_data = {
        "messages": [{"role": "user", "content": "æµ‹è¯•æ¶ˆæ¯"}],
        "temperature": 0.7
    }
    
    response = requests.post(
        f"{api_base_url}/api/v1/chat/completions",
        headers=headers,
        json=chat_data,
        timeout=30
    )
    
    assert response.status_code == 200
```text

### 3. ç«¯åˆ°ç«¯æµ‹è¯• (E2E Tests)

**ç›®æ ‡**ï¼šæµ‹è¯•å®Œæ•´çš„ç”¨æˆ·ä¸šåŠ¡æµç¨‹

**ä½ç½®**ï¼š`tests/e2e/`

**ç‰¹ç‚¹**ï¼š
- æ¨¡æ‹ŸçœŸå®ç”¨æˆ·æ“ä½œ
- è·¨å¤šä¸ªæœåŠ¡
- åŒ…å«UIäº¤äº’

**ç¤ºä¾‹**ï¼š

```python
# tests/e2e/test_complete_workflows.py
def test_complete_user_journey(self, service_config):
    """æµ‹è¯•å®Œæ•´ç”¨æˆ·æ—…ç¨‹"""
    # 1. ç”¨æˆ·æ³¨å†Œç™»å½•
    token = self.test_user_registration_and_login_flow(service_config, test_user_data)
    
    # 2. æ–‡æ¡£ä¸Šä¼ 
    self.test_document_management_workflow(service_config)
    
    # 3. æ™ºèƒ½é—®ç­”
    qa_results = self.test_intelligent_qa_workflow(service_config)
    
    # éªŒè¯æ•´ä½“æµç¨‹
    assert len(qa_results) > 0
    assert all(r["has_references"] for r in qa_results)
```text

## ğŸš€ æµ‹è¯•æ‰§è¡ŒæŒ‡å—

### å¿«é€Ÿå¼€å§‹ï¼ˆæ¨èæ–°ç”¨æˆ·ï¼‰

```bash
# æ–¹å¼ä¸€ï¼šä½¿ç”¨Makefileï¼ˆæœ€ç®€å•ï¼‰
make help                    # æŸ¥çœ‹æ‰€æœ‰å¯ç”¨å‘½ä»¤
make test-quick             # å¿«é€Ÿæµ‹è¯•éªŒè¯
make test                   # è¿è¡Œæ‰€æœ‰æµ‹è¯•
make test-unit              # åªè¿è¡Œå•å…ƒæµ‹è¯•

# æ–¹å¼äºŒï¼šå¿«é€Ÿæµ‹è¯•è„šæœ¬
./scripts/quick_test.sh     # å¿«é€ŸéªŒè¯æµ‹è¯•æ¡†æ¶å’Œæ ¸å¿ƒåŠŸèƒ½

# æ–¹å¼ä¸‰ï¼šæµ‹è¯•æ¼”ç¤º
python scripts/demo_tests.py  # äº¤äº’å¼æµ‹è¯•æ¼”ç¤ºå’Œç¯å¢ƒæ£€æŸ¥
```text

### ä½¿ç”¨å®Œæ•´æµ‹è¯•è„šæœ¬

```bash
# æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
./scripts/run_tests.sh --help

# æ£€æŸ¥ç¯å¢ƒå’Œä¾èµ–
./scripts/run_tests.sh --check

# è¿è¡Œæ‰€æœ‰æµ‹è¯•
./scripts/run_tests.sh --all

# è¿è¡Œç‰¹å®šç±»å‹æµ‹è¯•
./scripts/run_tests.sh --unit              # å•å…ƒæµ‹è¯•
./scripts/run_tests.sh --integration       # é›†æˆæµ‹è¯•
./scripts/run_tests.sh --e2e               # ç«¯åˆ°ç«¯æµ‹è¯•

# è¿è¡Œæ€§èƒ½æµ‹è¯•
./scripts/run_tests.sh --performance benchmark  # åŸºå‡†æµ‹è¯•
./scripts/run_tests.sh --performance load       # è´Ÿè½½æµ‹è¯•
./scripts/run_tests.sh --performance stress     # å‹åŠ›æµ‹è¯•

# ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
./scripts/run_tests.sh --report
```text

### ä½¿ç”¨pytestç›´æ¥æ‰§è¡Œ

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest

# è¿è¡Œç‰¹å®šç›®å½•çš„æµ‹è¯•
pytest tests/unit/
pytest tests/integration/
pytest tests/e2e/

# è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶
pytest tests/unit/backend/test_handlers.py

# è¿è¡Œç‰¹å®šæµ‹è¯•å‡½æ•°
pytest tests/unit/backend/test_handlers.py::TestAuthMiddleware::test_valid_jwt_token

# ä½¿ç”¨æ ‡è®°è¿‡æ»¤æµ‹è¯•
pytest -m "unit"           # åªè¿è¡Œå•å…ƒæµ‹è¯•
pytest -m "not slow"       # è·³è¿‡æ…¢é€Ÿæµ‹è¯•
pytest -m "api and not external"  # è¿è¡ŒAPIæµ‹è¯•ä½†è·³è¿‡å¤–éƒ¨ä¾èµ–

# å¹¶è¡Œæ‰§è¡Œæµ‹è¯•
pytest -n auto            # è‡ªåŠ¨æ£€æµ‹CPUæ ¸å¿ƒæ•°
pytest -n 4               # ä½¿ç”¨4ä¸ªè¿›ç¨‹

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=backend --cov=algo --cov-report=html

# è¯¦ç»†è¾“å‡º
pytest -v -s              # è¯¦ç»†è¾“å‡º + ä¸æ•è·stdout

# åªè¿è¡Œå¤±è´¥çš„æµ‹è¯•
pytest --lf               # last failed
pytest --ff               # failed first
```text

## âš¡ æ€§èƒ½æµ‹è¯•è¯¦è§£

### 1. åŸºå‡†æµ‹è¯• (Benchmark Tests)

**ç›®çš„**ï¼šå»ºç«‹æ€§èƒ½åŸºçº¿ï¼Œç”¨äºå›å½’æ£€æµ‹

```bash
# è¿è¡ŒåŸºå‡†æµ‹è¯•
python scripts/performance/benchmark_test.py

# é€‰æ‹©æµ‹è¯•æ¨¡å¼
# 1. å¿«é€ŸåŸºå‡†æµ‹è¯• (æ¨è)
# 2. å®Œæ•´åŸºå‡†æµ‹è¯•å¥—ä»¶  
# 3. è‡ªå®šä¹‰æµ‹è¯•
```text

**åŸºå‡†æŒ‡æ ‡**ï¼š
- å¥åº·æ£€æŸ¥ï¼š< 5ms
- èŠå¤©å®Œæˆï¼š< 2s
- æ–‡æ¡£æŸ¥è¯¢ï¼š< 1s
- å¹¶å‘å¤„ç†ï¼š> 100 QPS

### 2. è´Ÿè½½æµ‹è¯• (Load Tests)

**ç›®çš„**ï¼šéªŒè¯ç³»ç»Ÿåœ¨é¢„æœŸè´Ÿè½½ä¸‹çš„æ€§èƒ½

```bash
# ä½¿ç”¨Locustè¿›è¡Œè´Ÿè½½æµ‹è¯•
locust -f scripts/performance/load_test.py \
       --host http://localhost:8080 \
       --users 50 \
       --spawn-rate 5 \
       --run-time 5m \
       --headless

# æˆ–ä½¿ç”¨è„šæœ¬
./scripts/run_tests.sh --performance load
```text

**è´Ÿè½½é…ç½®**ï¼š
- å¹¶å‘ç”¨æˆ·ï¼š50
- å¯åŠ¨é€Ÿç‡ï¼š5ç”¨æˆ·/ç§’
- æŒç»­æ—¶é—´ï¼š5åˆ†é’Ÿ
- æˆåŠŸç‡ï¼š> 95%

### 3. å‹åŠ›æµ‹è¯• (Stress Tests)

**ç›®çš„**ï¼šæ‰¾å‡ºç³»ç»Ÿçš„æ€§èƒ½æé™å’Œå´©æºƒç‚¹

```bash
# è¿è¡Œå‹åŠ›æµ‹è¯•
python scripts/performance/stress_test.py

# æµ‹è¯•æ¨¡å¼é€‰æ‹©ï¼š
# 1. åç«¯å‹åŠ›æµ‹è¯•
# 2. ç®—æ³•æœåŠ¡å‹åŠ›æµ‹è¯•  
# 3. é€’å¢å‹åŠ›æµ‹è¯•
```text

**å‹åŠ›æµ‹è¯•åœºæ™¯**ï¼š
- é€’å¢è´Ÿè½½ï¼š10 â†’ 1000ç”¨æˆ·
- æé™å¹¶å‘ï¼šæ‰¾å‡ºæœ€å¤§QPS
- èµ„æºç›‘æ§ï¼šCPUã€å†…å­˜ã€ç½‘ç»œ

### æ€§èƒ½æµ‹è¯•æŠ¥å‘Š

æµ‹è¯•å®Œæˆåä¼šç”Ÿæˆä»¥ä¸‹æŠ¥å‘Šï¼š

```text
reports/
â”œâ”€â”€ benchmark_20241221_143022.json     # åŸºå‡†æµ‹è¯•ç»“æœ
â”œâ”€â”€ load_test_report_20241221_143500.csv   # è´Ÿè½½æµ‹è¯•è¯¦ç»†æ•°æ®
â”œâ”€â”€ stress_test_summary_20241221_144000.json  # å‹åŠ›æµ‹è¯•æ‘˜è¦
â””â”€â”€ performance_comparison.html        # æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š
```text

## ğŸ“Š æµ‹è¯•æŠ¥å‘Šåˆ†æ

### è¦†ç›–ç‡æŠ¥å‘Š

```bash
# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=backend --cov=algo --cov-report=html --cov-report=term

# æŸ¥çœ‹HTMLæŠ¥å‘Š
open reports/coverage_html/index.html
```text

**è¦†ç›–ç‡ç›®æ ‡**ï¼š
- æ•´ä½“è¦†ç›–ç‡ï¼š> 80%
- æ ¸å¿ƒæ¨¡å—ï¼š> 90%
- å…³é”®è·¯å¾„ï¼š100%

### æ€§èƒ½æŠ¥å‘Šåˆ†æ

**å…³é”®æŒ‡æ ‡**ï¼š

| æŒ‡æ ‡ | ç›®æ ‡å€¼ | è­¦å‘Šé˜ˆå€¼ | è¯´æ˜ |
|------|--------|----------|------|
| å¹³å‡å“åº”æ—¶é—´ | < 2s | > 3s | ç”¨æˆ·ä½“éªŒå…³é”®æŒ‡æ ‡ |
| P95å“åº”æ—¶é—´ | < 5s | > 8s | 95%è¯·æ±‚çš„å“åº”æ—¶é—´ |
| é”™è¯¯ç‡ | < 1% | > 5% | ç³»ç»Ÿç¨³å®šæ€§æŒ‡æ ‡ |
| ååé‡ | > 100 QPS | < 50 QPS | ç³»ç»Ÿå¤„ç†èƒ½åŠ› |
| CPUä½¿ç”¨ç‡ | < 70% | > 90% | èµ„æºä½¿ç”¨æ•ˆç‡ |
| å†…å­˜ä½¿ç”¨ç‡ | < 80% | > 95% | å†…å­˜æ³„æ¼æ£€æµ‹ |

### æµ‹è¯•è¶‹åŠ¿åˆ†æ

```python
# æ€§èƒ½è¶‹åŠ¿åˆ†æè„šæœ¬ç¤ºä¾‹
import pandas as pd
import matplotlib.pyplot as plt

# è¯»å–å†å²æµ‹è¯•æ•°æ®
df = pd.read_csv('reports/performance_history.csv')

# ç»˜åˆ¶å“åº”æ—¶é—´è¶‹åŠ¿
plt.figure(figsize=(12, 6))
plt.plot(df['date'], df['avg_response_time'], label='å¹³å‡å“åº”æ—¶é—´')
plt.plot(df['date'], df['p95_response_time'], label='P95å“åº”æ—¶é—´')
plt.xlabel('æ—¥æœŸ')
plt.ylabel('å“åº”æ—¶é—´ (ç§’)')
plt.title('VoiceHelper æ€§èƒ½è¶‹åŠ¿')
plt.legend()
plt.savefig('reports/performance_trend.png')
```text

## ğŸ”„ æŒç»­é›†æˆé…ç½®

### GitHub Actions é…ç½®

```yaml
# .github/workflows/test.yml
name: VoiceHelper Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  unit-tests:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        pip install -r requirements-test.txt
    
    - name: Run unit tests
      run: |
        pytest tests/unit/ --cov=backend --cov=algo --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3

  integration-tests:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Start services
      run: |
        # å¯åŠ¨åç«¯å’Œç®—æ³•æœåŠ¡
        docker-compose -f docker-compose.test.yml up -d
    
    - name: Run integration tests
      run: |
        pytest tests/integration/ -v

  performance-tests:
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Run benchmark tests
      run: |
        python scripts/performance/benchmark_test.py
    
    - name: Archive performance results
      uses: actions/upload-artifact@v3
      with:
        name: performance-reports
        path: reports/
```text

### æµ‹è¯•è´¨é‡é—¨ç¦

```yaml
# è´¨é‡é—¨ç¦é…ç½®
quality_gates:
  unit_tests:
    coverage_threshold: 80
    max_duration: 300  # 5åˆ†é’Ÿ
    
  integration_tests:
    success_rate: 95
    max_duration: 1800  # 30åˆ†é’Ÿ
    
  performance_tests:
    avg_response_time: 2.0  # 2ç§’
    error_rate: 1.0  # 1%
    throughput: 100  # 100 QPS
```text

## ğŸ¯ æœ€ä½³å®è·µ

### 1. æµ‹è¯•è®¾è®¡åŸåˆ™

**FIRSTåŸåˆ™**ï¼š
- **Fast**ï¼šæµ‹è¯•åº”è¯¥å¿«é€Ÿæ‰§è¡Œ
- **Independent**ï¼šæµ‹è¯•ä¹‹é—´ç›¸äº’ç‹¬ç«‹
- **Repeatable**ï¼šæµ‹è¯•ç»“æœå¯é‡å¤
- **Self-Validating**ï¼šæµ‹è¯•æœ‰æ˜ç¡®çš„é€šè¿‡/å¤±è´¥ç»“æœ
- **Timely**ï¼šæµ‹è¯•åº”è¯¥åŠæ—¶ç¼–å†™

### 2. æµ‹è¯•å‘½åè§„èŒƒ

```python
# å¥½çš„æµ‹è¯•å‘½å
def test_user_login_with_valid_credentials_returns_token():
    """æµ‹è¯•ï¼šä½¿ç”¨æœ‰æ•ˆå‡­æ®ç™»å½•åº”è¿”å›ä»¤ç‰Œ"""
    pass

def test_chat_completion_with_empty_message_raises_validation_error():
    """æµ‹è¯•ï¼šç©ºæ¶ˆæ¯çš„èŠå¤©å®Œæˆåº”æŠ›å‡ºéªŒè¯é”™è¯¯"""
    pass

# é¿å…çš„å‘½å
def test_login():  # å¤ªæ¨¡ç³Š
def test_case_1():  # æ— æ„ä¹‰
```text

### 3. æµ‹è¯•æ•°æ®ç®¡ç†

```python
# ä½¿ç”¨fixtureç®¡ç†æµ‹è¯•æ•°æ®
@pytest.fixture
def sample_user():
    return {
        "username": "test_user",
        "email": "test@example.com",
        "password": "secure_password"
    }

# ä½¿ç”¨å·¥å‚æ¨¡å¼ç”Ÿæˆæµ‹è¯•æ•°æ®
class UserFactory:
    @staticmethod
    def create_user(**kwargs):
        defaults = {
            "username": f"user_{random.randint(1000, 9999)}",
            "email": f"test_{random.randint(1000, 9999)}@example.com",
            "password": "test_password"
        }
        defaults.update(kwargs)
        return defaults
```text

### 4. å¼‚æ­¥æµ‹è¯•æœ€ä½³å®è·µ

```python
# æ­£ç¡®çš„å¼‚æ­¥æµ‹è¯•å†™æ³•
@pytest.mark.asyncio
async def test_async_chat_completion():
    """æµ‹è¯•å¼‚æ­¥èŠå¤©å®Œæˆ"""
    async with aiohttp.ClientSession() as session:
        response = await session.post("/api/chat", json={"message": "test"})
        assert response.status == 200

# ä½¿ç”¨è¶…æ—¶æ§åˆ¶
@pytest.mark.asyncio
@pytest.mark.timeout(30)
async def test_long_running_operation():
    """æµ‹è¯•é•¿æ—¶é—´è¿è¡Œçš„æ“ä½œ"""
    result = await long_running_function()
    assert result is not None
```text

### 5. é”™è¯¯å¤„ç†æµ‹è¯•

```python
def test_api_handles_invalid_input_gracefully():
    """æµ‹è¯•APIä¼˜é›…å¤„ç†æ— æ•ˆè¾“å…¥"""
    invalid_data = {"invalid": "data"}
    
    response = requests.post("/api/chat", json=invalid_data)
    
    assert response.status_code == 400
    assert "error" in response.json()
    assert "validation" in response.json()["error"].lower()
```text

### 6. æ€§èƒ½æµ‹è¯•æœ€ä½³å®è·µ

```python
def test_api_response_time_under_threshold():
    """æµ‹è¯•APIå“åº”æ—¶é—´åœ¨é˜ˆå€¼å†…"""
    start_time = time.time()
    
    response = requests.get("/api/health")
    
    response_time = time.time() - start_time
    assert response_time < 0.1  # 100msé˜ˆå€¼
    assert response.status_code == 200
```text

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### 1. æµ‹è¯•ç¯å¢ƒè¿æ¥å¤±è´¥

```bash
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl http://localhost:8080/health
curl http://localhost:8000/health

# æ£€æŸ¥ç«¯å£å ç”¨
netstat -tulpn | grep :8080
netstat -tulpn | grep :8000
```text

#### 2. æµ‹è¯•ä¾èµ–å®‰è£…å¤±è´¥

```bash
# å‡çº§pip
pip install --upgrade pip

# æ¸…ç†ç¼“å­˜é‡æ–°å®‰è£…
pip cache purge
pip install -r requirements-test.txt --no-cache-dir
```text

#### 3. å¼‚æ­¥æµ‹è¯•è¶…æ—¶

```python
# å¢åŠ è¶…æ—¶æ—¶é—´
@pytest.mark.timeout(60)
async def test_slow_operation():
    pass

# æˆ–åœ¨pytest.iniä¸­é…ç½®
# timeout = 60
```text

#### 4. è¦†ç›–ç‡ç»Ÿè®¡ä¸å‡†ç¡®

```bash
# æ¸…ç†ä¹‹å‰çš„è¦†ç›–ç‡æ•°æ®
coverage erase

# é‡æ–°è¿è¡Œæµ‹è¯•
pytest --cov=backend --cov=algo --cov-report=html
```text

## ğŸ› ï¸ æµ‹è¯•å·¥å…·è¯´æ˜

### æ–°å¢æµ‹è¯•å·¥å…·

#### 1. æµ‹è¯•æ¡†æ¶éªŒè¯

```bash
# éªŒè¯pytestå’Œç›¸å…³å·¥å…·æ˜¯å¦æ­£å¸¸å·¥ä½œ
python -m pytest tests/test_framework_validation.py -v
```text

#### 2. å¿«é€Ÿæµ‹è¯•è„šæœ¬

```bash
# å¿«é€ŸéªŒè¯æµ‹è¯•ç¯å¢ƒå’Œæ ¸å¿ƒåŠŸèƒ½
./scripts/quick_test.sh
```text

#### 3. æµ‹è¯•æ¼”ç¤ºè„šæœ¬

```bash
# äº¤äº’å¼æµ‹è¯•æ¼”ç¤ºï¼Œå±•ç¤ºå„ç§æµ‹è¯•ç±»å‹
python scripts/demo_tests.py
```text

#### 4. Makefileå‘½ä»¤

```bash
# æŸ¥çœ‹æ‰€æœ‰å¯ç”¨å‘½ä»¤
make help

# å¼€å‘ç¯å¢ƒè®¾ç½®
make dev-setup

# ä»£ç è´¨é‡æ£€æŸ¥
make lint format coverage

# æœåŠ¡ç®¡ç†
make start-backend start-algo start-frontend
make stop-services
```text

### æµ‹è¯•æ–‡ä»¶ç»“æ„

```text
tests/
â”œâ”€â”€ conftest.py                    # pytesté…ç½®å’Œfixtures
â”œâ”€â”€ test_framework_validation.py   # æµ‹è¯•æ¡†æ¶éªŒè¯
â”œâ”€â”€ unit/                          # å•å…ƒæµ‹è¯•
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â””â”€â”€ test_handlers.py
â”‚   â””â”€â”€ algo/
â”‚       â””â”€â”€ test_services.py
â”œâ”€â”€ integration/                   # é›†æˆæµ‹è¯•
â”‚   â””â”€â”€ test_api_endpoints.py
â””â”€â”€ e2e/                          # ç«¯åˆ°ç«¯æµ‹è¯•
    â””â”€â”€ test_complete_workflows.py

scripts/
â”œâ”€â”€ run_tests.sh                  # å®Œæ•´æµ‹è¯•è„šæœ¬
â”œâ”€â”€ quick_test.sh                 # å¿«é€Ÿæµ‹è¯•è„šæœ¬
â”œâ”€â”€ demo_tests.py                 # æµ‹è¯•æ¼”ç¤ºè„šæœ¬
â””â”€â”€ performance/                  # æ€§èƒ½æµ‹è¯•è„šæœ¬
    â”œâ”€â”€ load_test.py
    â”œâ”€â”€ stress_test.py
    â””â”€â”€ benchmark_test.py
```text

## ğŸ“š å‚è€ƒèµ„æº

- [pytestå®˜æ–¹æ–‡æ¡£](https://docs.pytest.org/)
- [Locustæ€§èƒ½æµ‹è¯•æŒ‡å—](https://docs.locust.io/)
- [Selenium WebDriveræ–‡æ¡£](https://selenium-python.readthedocs.io/)
- [aiohttpæµ‹è¯•æŒ‡å—](https://docs.aiohttp.org/en/stable/testing.html)
- [æµ‹è¯•é©±åŠ¨å¼€å‘æœ€ä½³å®è·µ](https://testdriven.io/)
- [Makeå‘½ä»¤æ•™ç¨‹](https://www.gnu.org/software/make/manual/)

---

**æœ€åæ›´æ–°**: 2024-12-21  
**ç»´æŠ¤è€…**: VoiceHelper Team  
**ç‰ˆæœ¬**: v2.0.0
