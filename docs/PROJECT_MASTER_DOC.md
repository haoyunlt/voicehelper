# ğŸš€ æ™ºèƒ½èŠå¤©æœºå™¨äººç³»ç»Ÿ - å®Œæ•´æŠ€æœ¯æ–‡æ¡£ v2.0

> **æœ€åæ›´æ–°**: 2025-09-21  
> **ç‰ˆæœ¬**: v1.4.0 (Production Ready) â†’ v2.0 (Industry Leading)  
> **çŠ¶æ€**: ç”Ÿäº§å°±ç»ªï¼ŒæŒç»­ä¼˜åŒ–ä¸­

---

## ğŸ“‹ ç›®å½•

1. [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
2. [ç³»ç»Ÿæ¶æ„](#ç³»ç»Ÿæ¶æ„)
3. [æ ¸å¿ƒåŠŸèƒ½](#æ ¸å¿ƒåŠŸèƒ½)
4. [æŠ€æœ¯å®ç°](#æŠ€æœ¯å®ç°)
5. [APIæ¥å£è§„èŒƒ](#apiæ¥å£è§„èŒƒ)
6. [éƒ¨ç½²æ–¹æ¡ˆ](#éƒ¨ç½²æ–¹æ¡ˆ)
7. [æ€§èƒ½æŒ‡æ ‡](#æ€§èƒ½æŒ‡æ ‡)
8. [ä¼˜åŒ–æ–¹æ¡ˆ](#ä¼˜åŒ–æ–¹æ¡ˆ)
9. [å¼€å‘æŒ‡å—](#å¼€å‘æŒ‡å—)
10. [è¿ç»´æ‰‹å†Œ](#è¿ç»´æ‰‹å†Œ)

---

## 1. é¡¹ç›®æ¦‚è¿°

### 1.1 é¡¹ç›®å®šä½
ä¼ä¸šçº§æ™ºèƒ½å¯¹è¯ç³»ç»Ÿï¼Œæ”¯æŒæ–‡æœ¬/è¯­éŸ³åŒæ¨¡æ€äº¤äº’ï¼Œå…·å¤‡é«˜çº§RAGæ£€ç´¢ã€è‡ªä¸»Agentèƒ½åŠ›ã€æŒç»­å­¦ä¹ æœºåˆ¶ï¼Œå¯¹æ ‡ä¸šç•Œé¢†å…ˆçš„AIåŠ©æ‰‹äº§å“ã€‚

### 1.2 æ ¸å¿ƒä»·å€¼
- **ğŸ¯ ä¸šåŠ¡ä»·å€¼**: 7Ã—24å°æ—¶æ™ºèƒ½å®¢æœï¼Œé™ä½80%äººå·¥æˆæœ¬
- **ğŸš€ æŠ€æœ¯åˆ›æ–°**: GraphRAG+è¿ç»­å­¦ä¹ ï¼Œä¸šç•Œé¦–åˆ›æ¶æ„
- **ğŸ’° æˆæœ¬ä¼˜åŒ–**: æ™ºèƒ½è·¯ç”±é™ä½50%LLMè°ƒç”¨æˆæœ¬
- **âš¡ æè‡´æ€§èƒ½**: é¦–å“<200msï¼Œä¸šç•Œæœ€å¿«

### 1.3 æŠ€æœ¯æ ˆ
```yaml
å‰ç«¯:
  Web: Next.js 14 + TypeScript + TailwindCSS + Framer Motion
  å°ç¨‹åº: åŸç”Ÿå¾®ä¿¡å°ç¨‹åº + WebAudio API
  
åç«¯:
  ç½‘å…³: Go 1.21 + Gin + WebSocket
  ç®—æ³•: Python 3.11 + FastAPI + LangChain + LangGraph
  
æ•°æ®:
  å‘é‡åº“: Milvus 2.3.4 + HNSWç´¢å¼•
  å›¾æ•°æ®åº“: Neo4j 5.0 (GraphRAG)
  å…³ç³»åº“: PostgreSQL 15 + åˆ†åŒºè¡¨
  ç¼“å­˜: Redis 7 + åˆ†å±‚ç¼“å­˜
  
AI:
  LLM: è±†åŒ…(Ark) + GPT-4 + æ™ºèƒ½è·¯ç”±
  åµŒå…¥: BGE-M3 + è‡ªé€‚åº”Fine-tuning
  è¯­éŸ³: ASR(FunASR) + TTS(Edge-TTS)
  
åŸºç¡€è®¾æ–½:
  å®¹å™¨: Docker + Kubernetes 1.28
  ç›‘æ§: Prometheus + Grafana + OpenTelemetry
  CI/CD: GitHub Actions + ArgoCD
```

---

## 2. ç³»ç»Ÿæ¶æ„

### 2.1 æ€»ä½“æ¶æ„å›¾
```mermaid
graph TB
    subgraph "å®¢æˆ·ç«¯å±‚"
        Web[Webåº”ç”¨<br/>Next.js]
        MP[å¾®ä¿¡å°ç¨‹åº]
        API[APIå®¢æˆ·ç«¯]
    end
    
    subgraph "ç½‘å…³å±‚"
        GW[APIç½‘å…³<br/>Go/Gin]
        Auth[è®¤è¯ä¸­å¿ƒ<br/>JWT/OIDC]
        RateLimit[é™æµå™¨]
    end
    
    subgraph "ä¸šåŠ¡å±‚"
        Chat[å¯¹è¯æœåŠ¡]
        Voice[è¯­éŸ³æœåŠ¡]
        Agent[Agentç¼–æ’]
    end
    
    subgraph "ç®—æ³•å±‚"
        RAG[RAGæ£€ç´¢<br/>GraphRAG]
        LLM[LLMæœåŠ¡<br/>å¤šæ¨¡å‹]
        ASR[è¯­éŸ³è¯†åˆ«]
        TTS[è¯­éŸ³åˆæˆ]
        Learn[ä¸»åŠ¨å­¦ä¹ ]
    end
    
    subgraph "æ•°æ®å±‚"
        PG[(PostgreSQL<br/>ä¸šåŠ¡æ•°æ®)]
        Milvus[(Milvus<br/>å‘é‡)]
        Neo4j[(Neo4j<br/>çŸ¥è¯†å›¾è°±)]
        Redis[(Redis<br/>ç¼“å­˜)]
    end
    
    Web --> GW
    MP --> GW
    API --> GW
    GW --> Auth
    GW --> RateLimit
    GW --> Chat
    GW --> Voice
    Chat --> Agent
    Voice --> Agent
    Agent --> RAG
    Agent --> LLM
    Voice --> ASR
    Voice --> TTS
    RAG --> Learn
    RAG --> Milvus
    RAG --> Neo4j
    Chat --> PG
    Chat --> Redis
```

### 2.2 å¾®æœåŠ¡åˆ’åˆ†

| æœåŠ¡åç§° | æŠ€æœ¯æ ˆ | ç«¯å£ | èŒè´£ |
|---------|--------|------|------|
| gateway | Go/Gin | 8080 | APIè·¯ç”±ã€è®¤è¯ã€é™æµã€ç›‘æ§ |
| algo-service | Python/FastAPI | 8000 | LLMè°ƒç”¨ã€RAGæ£€ç´¢ã€Agentç¼–æ’ |
| voice-service | Python/FastAPI | 8001 | ASR/TTSå¤„ç†ã€éŸ³é¢‘æµç®¡ç† |
| admin-service | Python/Flask | 5001 | è¿è¥åå°ã€æ•°æ®åˆ†æ |
| frontend | Next.js | 3000 | Webç”¨æˆ·ç•Œé¢ |

### 2.3 æ•°æ®æµè®¾è®¡

#### æ–‡æœ¬å¯¹è¯æµç¨‹
```
ç”¨æˆ·è¾“å…¥ â†’ ç½‘å…³éªŒè¯ â†’ è¯­ä¹‰ç¼“å­˜æ£€æŸ¥ â†’ RAGæ£€ç´¢ â†’ LLMç”Ÿæˆ â†’ æµå¼è¾“å‡º
                          â†“(miss)
                      GraphRAGæ£€ç´¢ â†’ çŸ¥è¯†èåˆ
```

#### è¯­éŸ³å¯¹è¯æµç¨‹
```
éŸ³é¢‘æµ â†’ WebSocket â†’ ASRå®æ—¶è½¬å†™ â†’ è¯­ä¹‰ç†è§£ â†’ Agentå¤„ç†
                           â†“
                    TTSåˆæˆ â† LLMç”Ÿæˆ â† RAGæ£€ç´¢
                           â†“
                    éŸ³é¢‘æµè¾“å‡ºï¼ˆå¯æ‰“æ–­ï¼‰
```

---

## 3. æ ¸å¿ƒåŠŸèƒ½

### 3.1 åŒæ¨¡æ€å¯¹è¯ âœ…
- **æ–‡æœ¬æ¨¡å¼**: SSEæµå¼è¾“å‡ºï¼Œæ”¯æŒMarkdownæ¸²æŸ“
- **è¯­éŸ³æ¨¡å¼**: WebSocketå…¨åŒå·¥ï¼Œæ”¯æŒbarge-inæ‰“æ–­
- **æ¨¡æ€åˆ‡æ¢**: åŒä¼šè¯æ— ç¼åˆ‡æ¢ï¼Œä¸Šä¸‹æ–‡ä¿æŒ

### 3.2 GraphRAGæ£€ç´¢ç³»ç»Ÿ ğŸ†•
```python
# æ ¸å¿ƒèƒ½åŠ›
- å®ä½“æŠ½å–: 10ç§å®ä½“ç±»å‹è‡ªåŠ¨è¯†åˆ«
- å…³ç³»æ„å»º: 15ç§å…³ç³»ç±»å‹ï¼Œç½®ä¿¡åº¦è¯„åˆ†
- å›¾éå†: å¤šè·³æ¨ç†ï¼Œè·¯å¾„è§£é‡Š
- ç¤¾åŒºå‘ç°: Louvainç®—æ³•ï¼Œä¸»é¢˜èšç±»
- èåˆæ’åº: å¤šè·¯å¬å›ï¼Œæ™ºèƒ½é‡æ’
```

### 3.3 å¢å¼ºAgentç³»ç»Ÿ âœ…
```yaml
æ¨ç†èƒ½åŠ›:
  - æ¼”ç»æ¨ç†: ä»è§„åˆ™æ¨å¯¼ç»“è®º
  - å½’çº³æ¨ç†: ä»æ¡ˆä¾‹æ€»ç»“è§„å¾‹
  - æº¯å› æ¨ç†: ä»ç°è±¡æ¨æµ‹åŸå› 
  - ç±»æ¯”æ¨ç†: è·¨é¢†åŸŸçŸ¥è¯†è¿ç§»

è§„åˆ’èƒ½åŠ›:
  - å±‚æ¬¡è§„åˆ’: ç›®æ ‡åˆ†è§£ï¼Œä¾èµ–ç®¡ç†
  - ååº”è§„åˆ’: å®æ—¶è°ƒæ•´ï¼ŒåŠ¨æ€é€‚åº”
  - æ·±æ€è§„åˆ’: é•¿æœŸå½±å“ï¼Œå…¨å±€ä¼˜åŒ–
  - æ··åˆè§„åˆ’: å¤šç­–ç•¥ç»„åˆ

è®°å¿†ç³»ç»Ÿ:
  - çŸ­æœŸè®°å¿†: ä¼šè¯ä¸Šä¸‹æ–‡(100æ¡)
  - é•¿æœŸè®°å¿†: æŒä¹…åŒ–çŸ¥è¯†(10000æ¡)
  - æƒ…èŠ‚è®°å¿†: äº¤äº’å†å²å›æ”¾
  - è¯­ä¹‰è®°å¿†: æ¦‚å¿µå…³ç³»ç½‘ç»œ
  - å·¥ä½œè®°å¿†: å½“å‰ä»»åŠ¡çŠ¶æ€
```

### 3.4 è¿ç»­å­¦ä¹ ç³»ç»Ÿ ğŸ†•
- **ä¸»åŠ¨å­¦ä¹ **: ä¸ç¡®å®šæ€§é‡‡æ ·ï¼ŒäººæœºååŒæ ‡æ³¨
- **åœ¨çº¿å­¦ä¹ **: å®æ—¶åé¦ˆï¼Œå¢é‡æ›´æ–°
- **è¿ç§»å­¦ä¹ **: é¢†åŸŸé€‚åº”ï¼Œå¿«é€Ÿæ”¶æ•›
- **è”é‚¦å­¦ä¹ **: éšç§ä¿æŠ¤ï¼Œåˆ†å¸ƒå¼è®­ç»ƒ

### 3.5 MCPå·¥å…·ç”Ÿæ€ âœ…
```javascript
// å·²å®ç°å·¥å…·
filesystem: æ–‡ä»¶è¯»å†™ã€ç›®å½•æ“ä½œ
http: APIè°ƒç”¨ã€ç½‘é¡µæŠ“å–
database: SQLæŸ¥è¯¢ã€æ•°æ®åˆ†æ
github: ä»£ç æ£€ç´¢ã€PRç®¡ç†
calculator: æ•°å­¦è®¡ç®—ã€ç»Ÿè®¡åˆ†æ
weather: å¤©æ°”æŸ¥è¯¢ã€é¢„æŠ¥
translation: å¤šè¯­è¨€ç¿»è¯‘
```

---

## 4. æŠ€æœ¯å®ç°

### 4.1 é«˜æ€§èƒ½ä¼˜åŒ–

#### 4.1.1 è¯­ä¹‰ç¼“å­˜
```python
class SemanticCache:
    """å¤šå±‚è¯­ä¹‰ç¼“å­˜"""
    
    def __init__(self):
        self.L1_memory = {}      # å†…å­˜ç¼“å­˜ï¼Œ<1ms
        self.L2_redis = Redis()  # Redisç¼“å­˜ï¼Œ<10ms
        self.L3_disk = DiskCache() # ç£ç›˜ç¼“å­˜ï¼Œ<100ms
        
    async def get(self, query: str):
        # 1. æŸ¥è¯¢æ ‡å‡†åŒ–
        normalized = self.normalize(query)
        
        # 2. ç²¾ç¡®åŒ¹é…
        if exact_match := self.L1_memory.get(normalized):
            return exact_match
            
        # 3. è¯­ä¹‰åŒ¹é…(ç›¸ä¼¼åº¦>0.92)
        if similar := await self.semantic_search(normalized):
            return similar
            
        return None
```

#### 4.1.2 æ™ºèƒ½æ¨¡å‹è·¯ç”±
```go
type ModelRouter struct {
    models []Model
    
    // è·¯ç”±ç­–ç•¥
    Strategy struct {
        CostWeight    float64 // æˆæœ¬æƒé‡
        QualityWeight float64 // è´¨é‡æƒé‡
        LatencyWeight float64 // å»¶è¿Ÿæƒé‡
    }
}

func (r *ModelRouter) Route(request Request) Model {
    complexity := r.analyzeComplexity(request)
    
    switch {
    case complexity < 0.3:
        return r.selectModel("gpt-3.5-turbo") // ç®€å•ä»»åŠ¡
    case complexity < 0.7:
        return r.selectModel("gpt-4")         // ä¸­ç­‰ä»»åŠ¡
    default:
        return r.selectModel("gpt-4-turbo")   // å¤æ‚ä»»åŠ¡
    }
}
```

#### 4.1.3 æ‰¹å¤„ç†ä¼˜åŒ–
```python
class BatchProcessor:
    """æ‰¹å¤„ç†ä¼˜åŒ–å™¨"""
    
    def __init__(self, batch_size=10, timeout=100):
        self.batch_size = batch_size
        self.timeout = timeout  # ms
        self.queue = asyncio.Queue()
        
    async def process_batch(self):
        batch = []
        deadline = time.time() + self.timeout/1000
        
        while len(batch) < self.batch_size and time.time() < deadline:
            try:
                item = await asyncio.wait_for(
                    self.queue.get(),
                    timeout=deadline - time.time()
                )
                batch.append(item)
            except asyncio.TimeoutError:
                break
                
        if batch:
            # æ‰¹é‡å¤„ç†ï¼Œå‡å°‘LLMè°ƒç”¨æ¬¡æ•°
            results = await self.llm.batch_generate(batch)
            return results
```

### 4.2 å®‰å…¨æœºåˆ¶

#### 4.2.1 å½¢å¼åŒ–éªŒè¯
```python
from z3 import *

class FormalVerifier:
    """å½¢å¼åŒ–éªŒè¯ç³»ç»Ÿ"""
    
    def verify_tool_call(self, tool: str, params: dict) -> bool:
        solver = Solver()
        
        # å®šä¹‰çº¦æŸ
        constraints = [
            # æƒé™çº¦æŸ
            self.has_permission(tool),
            # å‚æ•°çº¦æŸ
            self.validate_params(params),
            # å®‰å…¨çº¦æŸ
            Not(self.is_dangerous(tool, params))
        ]
        
        solver.add(And(constraints))
        
        # æ±‚è§£
        if solver.check() == sat:
            return True
        else:
            violations = solver.unsat_core()
            raise SecurityError(f"è¿åçº¦æŸ: {violations}")
```

#### 4.2.2 å¯¹æŠ—æ€§é˜²å¾¡
```python
class AdversarialDefense:
    """å¯¹æŠ—æ€§é˜²å¾¡ç³»ç»Ÿ"""
    
    def __init__(self):
        self.detectors = [
            PromptInjectionDetector(),
            JailbreakDetector(),
            ToxicityDetector(),
            PIILeakageDetector()
        ]
        
    async def defend(self, input_text: str) -> str:
        # 1. è¾“å…¥æ£€æµ‹
        for detector in self.detectors:
            if threat := detector.detect(input_text):
                logger.warning(f"æ£€æµ‹åˆ°å¨èƒ: {threat}")
                input_text = detector.sanitize(input_text)
        
        # 2. è¾“å‡ºè¿‡æ»¤
        output = await self.process(input_text)
        output = self.filter_sensitive(output)
        
        return output
```

---

## 5. APIæ¥å£è§„èŒƒ

### 5.1 RESTful API

#### åŸºç¡€è·¯å¾„
```
https://api.chatbot.example.com/api/v1
```

#### è®¤è¯æ–¹å¼
```http
Authorization: Bearer <JWT_TOKEN>
X-Tenant-ID: <TENANT_ID>
X-Request-ID: <REQUEST_ID>
```

### 5.2 æ ¸å¿ƒæ¥å£

#### 5.2.1 æ–‡æœ¬å¯¹è¯æµå¼æ¥å£
```http
POST /api/v1/chat/stream
Content-Type: application/json
Accept: text/event-stream

{
    "conversation_id": "conv_123",
    "messages": [
        {
            "role": "user",
            "content": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹RAGæŠ€æœ¯"
        }
    ],
    "stream": true,
    "temperature": 0.7,
    "top_k": 5,
    "use_graph_rag": true,
    "use_cache": true
}

# SSEå“åº”
data: {"type": "delta", "content": "RAGï¼ˆRetrieval", "seq": 1}
data: {"type": "delta", "content": "-Augmented Generationï¼‰", "seq": 2}
data: {"type": "refs", "references": [...], "seq": 3}
data: {"type": "done", "usage": {...}, "seq": 4}
```

#### 5.2.2 è¯­éŸ³å¯¹è¯WebSocket
```javascript
// è¿æ¥
const ws = new WebSocket('wss://api.chatbot.example.com/api/v1/voice/stream');

// å¼€å§‹ä¼šè¯
ws.send(JSON.stringify({
    type: 'start',
    conversation_id: 'conv_123',
    codec: 'opus',
    sample_rate: 16000,
    lang: 'zh-CN',
    vad: {
        enable: true,
        min_speech_ms: 200,
        min_silence_ms: 250
    }
}));

// å‘é€éŸ³é¢‘
ws.send(JSON.stringify({
    type: 'audio',
    seq: 1,
    chunk: '<base64_audio_data>'
}));

// æ¥æ”¶å“åº”
ws.onmessage = (event) => {
    const msg = JSON.parse(event.data);
    switch(msg.type) {
        case 'asr_partial': // å®æ—¶è½¬å†™
        case 'asr_final':   // æœ€ç»ˆè¯†åˆ«
        case 'llm_delta':   // LLMè¾“å‡º
        case 'tts_chunk':   // TTSéŸ³é¢‘
        case 'done':        // å®Œæˆ
    }
};
```

#### 5.2.3 GraphRAGæ£€ç´¢æ¥å£
```http
POST /api/v1/search/graph
Content-Type: application/json

{
    "query": "é¡¹ç›®ç®¡ç†æœ€ä½³å®è·µ",
    "search_type": "hybrid",  // vector|graph|hybrid
    "graph_options": {
        "max_hops": 2,
        "use_community": true,
        "use_path_reasoning": true
    },
    "top_k": 10,
    "filters": {
        "entity_types": ["æ¦‚å¿µ", "æµç¨‹"],
        "date_range": "2024-01-01/2025-01-01"
    }
}

# å“åº”
{
    "results": [
        {
            "content": "...",
            "score": 0.95,
            "source": "graph_traversal",
            "graph_context": {
                "entities": ["é¡¹ç›®ç®¡ç†", "æ•æ·å¼€å‘"],
                "relations": ["åŒ…å«", "å®ç°"],
                "path": ["é¡¹ç›®ç®¡ç†->æ•æ·å¼€å‘->Scrum"]
            }
        }
    ],
    "metadata": {
        "total_nodes_explored": 156,
        "communities_found": 3,
        "execution_time_ms": 45
    }
}
```

#### 5.2.4 Agentç¼–æ’æ¥å£
```http
POST /api/v1/agent/execute
Content-Type: application/json

{
    "task": "åˆ†ææœ€è¿‘ä¸€å‘¨çš„é”€å”®æ•°æ®å¹¶ç”ŸæˆæŠ¥å‘Š",
    "agent_config": {
        "capabilities": ["reasoning", "planning", "tool_use"],
        "max_iterations": 5,
        "confidence_threshold": 0.8
    },
    "tools": ["database", "calculator", "chart_generator"],
    "output_format": "markdown"
}

# å“åº”ï¼ˆSSEæµå¼ï¼‰
data: {"type": "plan", "steps": [...]}
data: {"type": "reasoning", "chain": [...]}
data: {"type": "tool_call", "tool": "database", "params": {...}}
data: {"type": "result", "content": "..."}
data: {"type": "done", "summary": {...}}
```

### 5.3 ç®¡ç†æ¥å£

#### 5.3.1 çŸ¥è¯†åº“ç®¡ç†
```http
# ä¸Šä¼ æ–‡æ¡£
POST /api/v1/knowledge/upload
Content-Type: multipart/form-data

# æ„å»ºç´¢å¼•
POST /api/v1/knowledge/index
{
    "dataset_id": "ds_123",
    "index_type": "graph",  // vector|graph|hybrid
    "options": {
        "chunk_size": 512,
        "overlap": 50,
        "extract_entities": true,
        "build_graph": true
    }
}

# æŸ¥è¯¢çŠ¶æ€
GET /api/v1/knowledge/status/{dataset_id}
```

#### 5.3.2 æ¨¡å‹ç®¡ç†
```http
# åˆ‡æ¢æ¨¡å‹
PUT /api/v1/models/switch
{
    "model_id": "gpt-4-turbo",
    "routing_strategy": "cost_optimized"
}

# è·å–æ¨¡å‹åˆ—è¡¨
GET /api/v1/models

# æ¨¡å‹æ€§èƒ½ç»Ÿè®¡
GET /api/v1/models/stats
```

---

## 6. éƒ¨ç½²æ–¹æ¡ˆ

### 6.1 å®¹å™¨åŒ–éƒ¨ç½²

#### Docker Compose (å¼€å‘ç¯å¢ƒ)
```yaml
version: '3.8'

services:
  gateway:
    build: ./backend
    ports:
      - "8080:8080"
    environment:
      - ENV=development
      - ALGO_SERVICE_URL=http://algo:8000
    depends_on:
      - redis
      - postgres
      
  algo:
    build: ./algo
    ports:
      - "8000:8000"
    volumes:
      - model-cache:/root/.cache
    environment:
      - MILVUS_HOST=milvus
      - NEO4J_URI=bolt://neo4j:7687
      
  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8080
      
  milvus:
    image: milvusdb/milvus:v2.3.4
    ports:
      - "19530:19530"
    volumes:
      - milvus-data:/var/lib/milvus
      
  neo4j:
    image: neo4j:5.0
    ports:
      - "7474:7474"
      - "7687:7687"
    environment:
      - NEO4J_AUTH=neo4j/password
    volumes:
      - neo4j-data:/data
      
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
      
  postgres:
    image: postgres:15
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=chatbot
      - POSTGRES_USER=chatbot
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./deploy/database/schema.sql:/docker-entrypoint-initdb.d/schema.sql

volumes:
  model-cache:
  milvus-data:
  neo4j-data:
  redis-data:
  postgres-data:
```

### 6.2 Kuberneteséƒ¨ç½² (ç”Ÿäº§ç¯å¢ƒ)

#### Helm Charté…ç½®
```yaml
# values.yaml
global:
  environment: production
  domain: chatbot.example.com

gateway:
  replicas: 3
  resources:
    requests:
      cpu: 500m
      memory: 512Mi
    limits:
      cpu: 1000m
      memory: 1Gi
  autoscaling:
    enabled: true
    minReplicas: 3
    maxReplicas: 10
    targetCPUUtilization: 60

algo:
  replicas: 2
  resources:
    requests:
      cpu: 1000m
      memory: 2Gi
    limits:
      cpu: 2000m
      memory: 4Gi
  gpu:
    enabled: true
    type: nvidia.com/gpu
    count: 1

ingress:
  enabled: true
  className: nginx
  tls:
    enabled: true
    secretName: chatbot-tls
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/proxy-body-size: 50m
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "300"

monitoring:
  prometheus:
    enabled: true
  grafana:
    enabled: true
    dashboards:
      - voice-metrics
      - rag-performance
      - cost-analysis
```

#### éƒ¨ç½²å‘½ä»¤
```bash
# åˆ›å»ºå‘½åç©ºé—´
kubectl create namespace chatbot-prod

# å®‰è£…Helm Chart
helm install chatbot ./charts/chatbot \
  --namespace chatbot-prod \
  --values values.prod.yaml

# æ›´æ–°éƒ¨ç½²
helm upgrade chatbot ./charts/chatbot \
  --namespace chatbot-prod \
  --values values.prod.yaml

# å›æ»š
helm rollback chatbot 1 --namespace chatbot-prod
```

### 6.3 CI/CDæµç¨‹

```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    tags:
      - 'v*'

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Run Tests
        run: |
          make test
          make lint
          make security-scan
          
      - name: Contract Tests
        run: |
          make test-contracts
          
  build:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - name: Build Images
        run: |
          docker build -t gateway:${{ github.ref_name }} ./backend
          docker build -t algo:${{ github.ref_name }} ./algo
          docker build -t frontend:${{ github.ref_name }} ./frontend
          
      - name: Push to Registry
        run: |
          docker push registry.example.com/gateway:${{ github.ref_name }}
          docker push registry.example.com/algo:${{ github.ref_name }}
          docker push registry.example.com/frontend:${{ github.ref_name }}
          
  deploy:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to Kubernetes
        run: |
          kubectl set image deployment/gateway gateway=registry.example.com/gateway:${{ github.ref_name }}
          kubectl set image deployment/algo algo=registry.example.com/algo:${{ github.ref_name }}
          kubectl set image deployment/frontend frontend=registry.example.com/frontend:${{ github.ref_name }}
          
      - name: Wait for Rollout
        run: |
          kubectl rollout status deployment/gateway
          kubectl rollout status deployment/algo
          kubectl rollout status deployment/frontend
          
      - name: Run Smoke Tests
        run: |
          make test-smoke
```

---

## 7. æ€§èƒ½æŒ‡æ ‡

### 7.1 å½“å‰æ€§èƒ½åŸºå‡†

| æŒ‡æ ‡åˆ†ç±» | æŒ‡æ ‡åç§° | å½“å‰å€¼ | ç›®æ ‡å€¼ | SLO |
|---------|---------|--------|--------|-----|
| **å»¶è¿Ÿ** | æ–‡æœ¬é¦–Token | 500ms | 400ms | P95 < 800ms |
| | è¯­éŸ³é¦–å“ | 300ms | 200ms | P95 < 500ms |
| | ç«¯åˆ°ç«¯å¯¹è¯ | 2.0s | 1.5s | P95 < 2.5s |
| | Barge-inå“åº” | 150ms | 100ms | P99 < 200ms |
| **åå** | QPS | 1000 | 2000 | >500 |
| | å¹¶å‘è¿æ¥ | 5000 | 10000 | >2000 |
| | æ—¥å¤„ç†é‡ | 100ä¸‡ | 200ä¸‡ | >50ä¸‡ |
| **å‡†ç¡®æ€§** | RAGå¬å›ç‡ | 92% | 97% | >85% |
| | æ¨ç†å‡†ç¡®ç‡ | 85% | 94% | >80% |
| | ASRå‡†ç¡®ç‡ | 95% | 98% | >90% |
| **å¯ç”¨æ€§** | ç³»ç»Ÿå¯ç”¨æ€§ | 99.95% | 99.99% | >99.9% |
| | æ•…éšœæ¢å¤ | 5min | 2min | <10min |
| | æ•°æ®æŒä¹…æ€§ | 99.999% | 99.9999% | >99.99% |
| **æˆæœ¬** | æ¯è¯·æ±‚æˆæœ¬ | $0.01 | $0.005 | <$0.02 |
| | Tokenä½¿ç”¨ç‡ | 2000/req | 1000/req | <3000/req |
| | ç¼“å­˜å‘½ä¸­ç‡ | 75% | 85% | >60% |

### 7.2 æ€§èƒ½ä¼˜åŒ–è·¯çº¿å›¾

```mermaid
gantt
    title æ€§èƒ½ä¼˜åŒ–è·¯çº¿å›¾
    dateFormat  YYYY-MM-DD
    section ç¬¬ä¸€é˜¶æ®µ
    GraphRAGä¼˜åŒ–       :2025-01-01, 14d
    ç¼“å­˜ç³»ç»Ÿå‡çº§       :2025-01-08, 7d
    section ç¬¬äºŒé˜¶æ®µ
    æ¨¡å‹é‡åŒ–å‹ç¼©       :2025-01-15, 14d
    è¾¹ç¼˜è®¡ç®—éƒ¨ç½²       :2025-01-22, 7d
    section ç¬¬ä¸‰é˜¶æ®µ
    GPUæ¨ç†åŠ é€Ÿ        :2025-01-29, 14d
    åˆ†å¸ƒå¼è®­ç»ƒ        :2025-02-05, 7d
```

---

## 8. ä¼˜åŒ–æ–¹æ¡ˆ

### 8.1 åŸºäºä¸šç•Œæœ€æ–°æŠ€æœ¯çš„ä¼˜åŒ–

#### 8.1.1 è‡ªæˆ‘ä¿®æ­£æ¨ç†é“¾ ğŸ†•
```python
class SelfCorrectingChain:
    """è‡ªæˆ‘ä¿®æ­£æ¨ç†é“¾"""
    
    async def reason(self, query: str, max_iterations: int = 3):
        for i in range(max_iterations):
            # ç”Ÿæˆæ¨ç†
            reasoning = await self.generate_reasoning(query)
            
            # è‡ªæˆ‘è¯„ä¼°
            evaluation = await self.evaluate_reasoning(reasoning)
            
            if evaluation['confidence'] > 0.85:
                return reasoning
                
            # è¯†åˆ«é”™è¯¯
            errors = await self.identify_errors(reasoning, evaluation)
            
            # ä¿®æ­£é”™è¯¯
            query = self.apply_corrections(query, errors)
            
        return reasoning
```

#### 8.1.2 è”é‚¦å­¦ä¹ æ¶æ„ ğŸ†•
```python
class FederatedLearning:
    """è”é‚¦å­¦ä¹ ç³»ç»Ÿ"""
    
    def __init__(self):
        self.local_models = {}
        self.global_model = None
        
    async def train_local(self, tenant_id: str, data: List):
        """æœ¬åœ°è®­ç»ƒ"""
        model = self.local_models.get(tenant_id)
        
        # å·®åˆ†éšç§è®­ç»ƒ
        model = await self.train_with_privacy(model, data)
        
        # ç”Ÿæˆæ›´æ–°
        updates = self.compute_updates(model)
        
        return updates
        
    async def aggregate_global(self, all_updates: List):
        """å…¨å±€èšåˆ"""
        # å®‰å…¨èšåˆ
        aggregated = self.secure_aggregate(all_updates)
        
        # æ›´æ–°å…¨å±€æ¨¡å‹
        self.global_model = self.update_model(
            self.global_model,
            aggregated
        )
```

#### 8.1.3 å¤šæ¨¡æ€èåˆ ğŸ†•
```python
class MultiModalFusion:
    """å¤šæ¨¡æ€èåˆå¤„ç†"""
    
    async def process(
        self,
        text: Optional[str] = None,
        image: Optional[bytes] = None,
        audio: Optional[bytes] = None,
        video: Optional[bytes] = None
    ):
        embeddings = []
        
        # æ–‡æœ¬ç¼–ç 
        if text:
            text_emb = await self.encode_text(text)
            embeddings.append(('text', text_emb, 0.4))
            
        # å›¾åƒç¼–ç 
        if image:
            image_emb = await self.encode_image(image)
            embeddings.append(('image', image_emb, 0.3))
            
        # éŸ³é¢‘ç¼–ç 
        if audio:
            audio_emb = await self.encode_audio(audio)
            embeddings.append(('audio', audio_emb, 0.2))
            
        # è§†é¢‘ç¼–ç 
        if video:
            video_emb = await self.encode_video(video)
            embeddings.append(('video', video_emb, 0.1))
            
        # æ³¨æ„åŠ›èåˆ
        fused = self.attention_fusion(embeddings)
        
        return fused
```

### 8.2 æˆæœ¬ä¼˜åŒ–ç­–ç•¥

#### 8.2.1 æ™ºèƒ½Tokenç®¡ç†
```python
class TokenOptimizer:
    """Tokenä¼˜åŒ–å™¨"""
    
    def optimize_prompt(self, prompt: str, max_tokens: int = 2000):
        # 1. å‹ç¼©å†—ä½™
        compressed = self.compress_redundancy(prompt)
        
        # 2. æå–å…³é”®ä¿¡æ¯
        key_info = self.extract_key_information(compressed)
        
        # 3. åŠ¨æ€æˆªæ–­
        if len(key_info) > max_tokens:
            key_info = self.dynamic_truncate(key_info, max_tokens)
            
        return key_info
        
    def compress_redundancy(self, text: str):
        # å»é™¤é‡å¤å¥å­
        sentences = text.split('.')
        unique_sentences = list(dict.fromkeys(sentences))
        return '.'.join(unique_sentences)
```

#### 8.2.2 æ¨¡å‹çº§è”ç­–ç•¥
```yaml
æ¨¡å‹çº§è”:
  ç¬¬ä¸€çº§: 
    æ¨¡å‹: Qwen-7B
    åœºæ™¯: ç®€å•é—®ç­”ã€ä¿¡æ¯æŸ¥è¯¢
    æˆæœ¬: $0.001/1k tokens
    
  ç¬¬äºŒçº§:
    æ¨¡å‹: GPT-3.5-Turbo
    åœºæ™¯: å¤æ‚å¯¹è¯ã€å¤šè½®äº¤äº’
    æˆæœ¬: $0.002/1k tokens
    
  ç¬¬ä¸‰çº§:
    æ¨¡å‹: GPT-4
    åœºæ™¯: ä¸“ä¸šæ¨ç†ã€åˆ›æ„ç”Ÿæˆ
    æˆæœ¬: $0.03/1k tokens
    
  ç¬¬å››çº§:
    æ¨¡å‹: GPT-4-Vision
    åœºæ™¯: å¤šæ¨¡æ€ç†è§£
    æˆæœ¬: $0.05/1k tokens
```

---

## 9. å¼€å‘æŒ‡å—

### 9.1 å¿«é€Ÿå¼€å§‹

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/example/chatbot.git
cd chatbot

# å®‰è£…ä¾èµ–
make install

# é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘.envæ–‡ä»¶ï¼Œå¡«å…¥å¿…è¦çš„é…ç½®

# å¯åŠ¨å¼€å‘ç¯å¢ƒ
make dev

# è¿è¡Œæµ‹è¯•
make test

# æ„å»ºç”Ÿäº§ç‰ˆæœ¬
make build
```

### 9.2 å¼€å‘è§„èŒƒ

#### ä»£ç é£æ ¼
- **Go**: éµå¾ªå®˜æ–¹è§„èŒƒï¼Œä½¿ç”¨golangci-lint
- **Python**: PEP 8ï¼Œä½¿ç”¨black + isort
- **TypeScript**: ESLint + Prettier
- **æäº¤è§„èŒƒ**: Conventional Commits

#### åˆ†æ”¯ç®¡ç†
```
main (ä¿æŠ¤åˆ†æ”¯)
â”œâ”€â”€ feat/feature-name    # åŠŸèƒ½å¼€å‘
â”œâ”€â”€ fix/bug-description  # Bugä¿®å¤
â”œâ”€â”€ docs/doc-update      # æ–‡æ¡£æ›´æ–°
â”œâ”€â”€ perf/optimization    # æ€§èƒ½ä¼˜åŒ–
â””â”€â”€ refactor/module      # ä»£ç é‡æ„
```

#### æµ‹è¯•è¦æ±‚
- å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 80%
- é›†æˆæµ‹è¯•è¦†ç›–æ ¸å¿ƒæµç¨‹
- E2Eæµ‹è¯•è¦†ç›–å…³é”®è·¯å¾„
- æ€§èƒ½æµ‹è¯•åŸºå‡†å¿…é¡»é€šè¿‡

### 9.3 è°ƒè¯•æŠ€å·§

#### æ—¥å¿—çº§åˆ«
```python
import logging

# å¼€å‘ç¯å¢ƒ
logging.basicConfig(level=logging.DEBUG)

# ç”Ÿäº§ç¯å¢ƒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
```

#### æ€§èƒ½åˆ†æ
```python
import cProfile
import pstats

# æ€§èƒ½åˆ†æ
profiler = cProfile.Profile()
profiler.enable()

# æ‰§è¡Œä»£ç 
result = expensive_function()

profiler.disable()
stats = pstats.Stats(profiler)
stats.sort_stats('cumulative')
stats.print_stats(10)
```

---

## 10. è¿ç»´æ‰‹å†Œ

### 10.1 ç›‘æ§å‘Šè­¦

#### å…³é”®æŒ‡æ ‡ç›‘æ§
```yaml
å‘Šè­¦è§„åˆ™:
  - name: é«˜å»¶è¿Ÿå‘Šè­¦
    condition: p95_latency > 1000ms
    duration: 5m
    severity: warning
    
  - name: é”™è¯¯ç‡å‘Šè­¦
    condition: error_rate > 1%
    duration: 3m
    severity: critical
    
  - name: å†…å­˜ä½¿ç”¨å‘Šè­¦
    condition: memory_usage > 80%
    duration: 10m
    severity: warning
    
  - name: Tokenè¶…é™å‘Šè­¦
    condition: token_usage > daily_limit * 0.9
    duration: 1m
    severity: critical
```

#### Grafanaä»ªè¡¨æ¿
1. **ç³»ç»Ÿæ¦‚è§ˆ**: QPSã€å»¶è¿Ÿã€é”™è¯¯ç‡ã€å¯ç”¨æ€§
2. **ä¸šåŠ¡æŒ‡æ ‡**: ç”¨æˆ·æ•°ã€ä¼šè¯æ•°ã€æ»¡æ„åº¦
3. **èµ„æºç›‘æ§**: CPUã€å†…å­˜ã€ç£ç›˜ã€ç½‘ç»œ
4. **æˆæœ¬åˆ†æ**: Tokenä½¿ç”¨ã€APIè°ƒç”¨ã€å­˜å‚¨æˆæœ¬

### 10.2 æ•…éšœå¤„ç†

#### æ•…éšœå®šä½æµç¨‹
```mermaid
graph TD
    A[æ”¶åˆ°å‘Šè­¦] --> B{åˆ¤æ–­ä¸¥é‡ç¨‹åº¦}
    B -->|P0ç´§æ€¥| C[ç«‹å³å“åº”]
    B -->|P1é‡è¦| D[30åˆ†é’Ÿå†…å“åº”]
    B -->|P2ä¸€èˆ¬| E[2å°æ—¶å†…å“åº”]
    
    C --> F[æ£€æŸ¥ç›‘æ§é¢æ¿]
    D --> F
    E --> F
    
    F --> G[æŸ¥çœ‹é”™è¯¯æ—¥å¿—]
    G --> H[å®šä½é—®é¢˜æ¨¡å—]
    H --> I{æ˜¯å¦å¯å¿«é€Ÿä¿®å¤}
    
    I -->|æ˜¯| J[æ‰§è¡Œä¿®å¤]
    I -->|å¦| K[å¯åŠ¨å›æ»š]
    
    J --> L[éªŒè¯ä¿®å¤]
    K --> L
    L --> M[ç¼–å†™æ•…éšœæŠ¥å‘Š]
```

#### å¸¸è§é—®é¢˜å¤„ç†

| é—®é¢˜ | ç—‡çŠ¶ | è§£å†³æ–¹æ¡ˆ |
|------|------|----------|
| LLMè¶…æ—¶ | å“åº”æ—¶é—´>10s | 1. åˆ‡æ¢å¤‡ç”¨æ¨¡å‹<br>2. å¢åŠ è¶…æ—¶æ—¶é—´<br>3. å¯ç”¨ç¼“å­˜ |
| å†…å­˜æ³„æ¼ | å†…å­˜æŒç»­å¢é•¿ | 1. é‡å¯æœåŠ¡<br>2. åˆ†æheap dump<br>3. ä¿®å¤æ³„æ¼ä»£ç  |
| æ•°æ®åº“è¿æ¥æ± æ»¡ | è¿æ¥é”™è¯¯ | 1. å¢åŠ è¿æ¥æ± å¤§å°<br>2. ä¼˜åŒ–æ…¢æŸ¥è¯¢<br>3. æ·»åŠ è¯»å†™åˆ†ç¦» |
| ç¼“å­˜é›ªå´© | å¤§é‡è¯·æ±‚ç›´è¾¾DB | 1. å¯ç”¨å¤‡ç”¨ç¼“å­˜<br>2. é™æµé™çº§<br>3. ç¼“å­˜é¢„çƒ­ |

### 10.3 å¤‡ä»½æ¢å¤

#### å¤‡ä»½ç­–ç•¥
```yaml
æ•°æ®å¤‡ä»½:
  PostgreSQL:
    å…¨é‡å¤‡ä»½: æ¯æ—¥å‡Œæ™¨2ç‚¹
    å¢é‡å¤‡ä»½: æ¯å°æ—¶
    ä¿ç•™å‘¨æœŸ: 30å¤©
    
  Milvus:
    å¿«ç…§å¤‡ä»½: æ¯æ—¥ä¸€æ¬¡
    binlogå¤‡ä»½: å®æ—¶
    ä¿ç•™å‘¨æœŸ: 7å¤©
    
  Neo4j:
    å…¨é‡å¤‡ä»½: æ¯å‘¨ä¸€æ¬¡
    å¢é‡å¤‡ä»½: æ¯æ—¥
    ä¿ç•™å‘¨æœŸ: 14å¤©
    
  é…ç½®å¤‡ä»½:
    Gitä»“åº“: å®æ—¶
    åŠ å¯†å­˜å‚¨: S3
    ç‰ˆæœ¬æ§åˆ¶: å®Œæ•´å†å²
```

#### æ¢å¤æµç¨‹
```bash
# 1. åœæ­¢æœåŠ¡
kubectl scale deployment --all --replicas=0

# 2. æ¢å¤æ•°æ®åº“
pg_restore -h localhost -U chatbot -d chatbot backup.dump

# 3. æ¢å¤å‘é‡åº“
milvus-backup restore --backup-path s3://backup/milvus/20250121

# 4. æ¢å¤é…ç½®
kubectl apply -f backup/configs/

# 5. å¯åŠ¨æœåŠ¡
kubectl scale deployment --all --replicas=3

# 6. éªŒè¯æœåŠ¡
make test-smoke
```

### 10.4 å®¹é‡è§„åˆ’

#### èµ„æºè®¡ç®—å…¬å¼
```
CPUéœ€æ±‚ = QPS * å•è¯·æ±‚CPUæ—¶é—´ * å®‰å…¨ç³»æ•°(1.5)
å†…å­˜éœ€æ±‚ = å¹¶å‘æ•° * å•è¿æ¥å†…å­˜ + ç¼“å­˜å¤§å° + æ¨¡å‹å¤§å°
å­˜å‚¨éœ€æ±‚ = æ•°æ®å¢é•¿ç‡ * ä¿ç•™æœŸé™ + ç´¢å¼•å¤§å° * å‰¯æœ¬æ•°
å¸¦å®½éœ€æ±‚ = QPS * å¹³å‡è¯·æ±‚å¤§å° + QPS * å¹³å‡å“åº”å¤§å°
```

#### æ‰©å®¹å»ºè®®
| æŒ‡æ ‡ | é˜ˆå€¼ | æ‰©å®¹æ–¹æ¡ˆ |
|------|------|----------|
| CPUä½¿ç”¨ç‡ > 70% | æŒç»­5åˆ†é’Ÿ | HPAè‡ªåŠ¨æ‰©å®¹ |
| å†…å­˜ä½¿ç”¨ç‡ > 80% | æŒç»­10åˆ†é’Ÿ | å‚ç›´æ‰©å®¹ |
| QPS > 1000 | é¢„æœŸæŒç»­ | å¢åŠ å‰¯æœ¬æ•° |
| å­˜å‚¨ä½¿ç”¨ > 80% | - | æ‰©å®¹PV |

---

## é™„å½•

### A. é…ç½®ç¤ºä¾‹

#### A.1 ç¯å¢ƒå˜é‡é…ç½®
```bash
# .env.production
# åŸºç¡€é…ç½®
ENV=production
LOG_LEVEL=info
PORT=8080

# æ•°æ®åº“é…ç½®
POSTGRES_HOST=postgres.example.com
POSTGRES_PORT=5432
POSTGRES_DB=chatbot_prod
POSTGRES_USER=chatbot
POSTGRES_PASSWORD=${SECRET_POSTGRES_PASSWORD}

# Redisé…ç½®
REDIS_HOST=redis.example.com
REDIS_PORT=6379
REDIS_PASSWORD=${SECRET_REDIS_PASSWORD}
REDIS_DB=0

# Milvusé…ç½®
MILVUS_HOST=milvus.example.com
MILVUS_PORT=19530
MILVUS_TOKEN=${SECRET_MILVUS_TOKEN}

# Neo4jé…ç½®
NEO4J_URI=bolt://neo4j.example.com:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=${SECRET_NEO4J_PASSWORD}

# LLMé…ç½®
OPENAI_API_KEY=${SECRET_OPENAI_KEY}
ARK_API_KEY=${SECRET_ARK_KEY}
MODEL_ROUTER_STRATEGY=cost_optimized

# å®‰å…¨é…ç½®
JWT_SECRET=${SECRET_JWT_KEY}
ENCRYPTION_KEY=${SECRET_ENCRYPTION_KEY}
ALLOWED_ORIGINS=https://chatbot.example.com

# ç›‘æ§é…ç½®
PROMETHEUS_ENDPOINT=http://prometheus:9090
GRAFANA_ENDPOINT=http://grafana:3000
SENTRY_DSN=${SECRET_SENTRY_DSN}
```

### B. æ€§èƒ½æµ‹è¯•è„šæœ¬

```python
# performance_test.py
import asyncio
import time
import statistics
from concurrent.futures import ThreadPoolExecutor
import aiohttp

class PerformanceTester:
    def __init__(self, base_url: str, num_requests: int = 1000):
        self.base_url = base_url
        self.num_requests = num_requests
        self.latencies = []
        
    async def test_endpoint(self, session: aiohttp.ClientSession):
        start = time.time()
        
        async with session.post(
            f"{self.base_url}/api/v1/chat/stream",
            json={
                "messages": [{"role": "user", "content": "test"}],
                "stream": False
            }
        ) as response:
            await response.text()
            
        latency = (time.time() - start) * 1000
        self.latencies.append(latency)
        
    async def run_test(self):
        async with aiohttp.ClientSession() as session:
            tasks = [
                self.test_endpoint(session) 
                for _ in range(self.num_requests)
            ]
            
            start = time.time()
            await asyncio.gather(*tasks)
            duration = time.time() - start
            
        # è®¡ç®—ç»Ÿè®¡
        qps = self.num_requests / duration
        p50 = statistics.median(self.latencies)
        p95 = statistics.quantiles(self.latencies, n=20)[18]
        p99 = statistics.quantiles(self.latencies, n=100)[98]
        
        print(f"QPS: {qps:.2f}")
        print(f"P50: {p50:.2f}ms")
        print(f"P95: {p95:.2f}ms")
        print(f"P99: {p99:.2f}ms")

if __name__ == "__main__":
    tester = PerformanceTester("http://localhost:8080")
    asyncio.run(tester.run_test())
```

### C. æ•…éšœæ¼”ç»ƒè„šæœ¬

```bash
#!/bin/bash
# chaos_test.sh

echo "å¼€å§‹æ··æ²Œå·¥ç¨‹æµ‹è¯•..."

# 1. ç½‘ç»œå»¶è¿Ÿæ³¨å…¥
echo "æµ‹è¯•1: æ³¨å…¥ç½‘ç»œå»¶è¿Ÿ"
kubectl exec -it deployment/gateway -- tc qdisc add dev eth0 root netem delay 200ms
sleep 30
kubectl exec -it deployment/gateway -- tc qdisc del dev eth0 root

# 2. CPUå‹åŠ›æµ‹è¯•
echo "æµ‹è¯•2: CPUå‹åŠ›æµ‹è¯•"
kubectl exec -it deployment/algo -- stress --cpu 4 --timeout 60s

# 3. å†…å­˜å‹åŠ›æµ‹è¯•
echo "æµ‹è¯•3: å†…å­˜å‹åŠ›æµ‹è¯•"
kubectl exec -it deployment/algo -- stress --vm 2 --vm-bytes 1G --timeout 60s

# 4. éšæœºPodåˆ é™¤
echo "æµ‹è¯•4: éšæœºåˆ é™¤Pod"
kubectl delete pod $(kubectl get pods -l app=gateway -o jsonpath='{.items[0].metadata.name}')

# 5. æ•°æ®åº“è¿æ¥ä¸­æ–­
echo "æµ‹è¯•5: æ•°æ®åº“è¿æ¥ä¸­æ–­"
kubectl exec -it deployment/gateway -- iptables -A OUTPUT -p tcp --dport 5432 -j DROP
sleep 30
kubectl exec -it deployment/gateway -- iptables -D OUTPUT -p tcp --dport 5432 -j DROP

echo "æ··æ²Œæµ‹è¯•å®Œæˆï¼Œæ£€æŸ¥ç³»ç»Ÿæ¢å¤æƒ…å†µ..."
```

---

## æ€»ç»“

æœ¬æ–‡æ¡£æ•´åˆäº†æ™ºèƒ½èŠå¤©æœºå™¨äººç³»ç»Ÿçš„å®Œæ•´æŠ€æœ¯æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ï¼š

1. **æ ¸å¿ƒåŠŸèƒ½**: åŒæ¨¡æ€å¯¹è¯ã€GraphRAGã€å¢å¼ºAgentã€è¿ç»­å­¦ä¹ 
2. **æŠ€æœ¯å®ç°**: é«˜æ€§èƒ½ä¼˜åŒ–ã€å®‰å…¨æœºåˆ¶ã€æ™ºèƒ½è·¯ç”±
3. **éƒ¨ç½²æ–¹æ¡ˆ**: å®¹å™¨åŒ–ã€K8sç¼–æ’ã€CI/CDè‡ªåŠ¨åŒ–
4. **è¿ç»´æŒ‡å—**: ç›‘æ§å‘Šè­¦ã€æ•…éšœå¤„ç†ã€å®¹é‡è§„åˆ’

ç³»ç»Ÿå·²è¾¾åˆ°**ç”Ÿäº§å°±ç»ª**çŠ¶æ€ï¼Œæ­£åœ¨å‘**ä¸šç•Œé¢†å…ˆ**æ°´å¹³è¿ˆè¿›ã€‚

---

*æ–‡æ¡£ç‰ˆæœ¬: 2.0*  
*æœ€åæ›´æ–°: 2025-09-21*  
*ç»´æŠ¤å›¢é˜Ÿ: AI Platform Team*
